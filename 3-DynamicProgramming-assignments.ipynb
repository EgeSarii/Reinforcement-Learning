{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EgeSarii/Reinforcement-Learning/blob/main/3-DynamicProgramming-assignments.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "C0tJn-yZP5HY"
      },
      "source": [
        "## Reinforcement Learning 3: *Dynamic Programming*\n",
        "\n",
        "**Assignment:** hand-in before 21/02/2022"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "JcS8BtkXP5Hc"
      },
      "source": [
        "#### **1. Frozen Lake**\n",
        "\n",
        "*(5 x 1 points)*\n",
        "\n",
        "The Frozen Lake environment is a 4×4 grid which contain four possible areas  — Safe (S), Frozen (F), Hole (H) and Goal (G). The agent moves around the grid until it reaches the goal or the hole. The agent in the environment has four possible moves — Up, Down, Left and Right. If it falls into the hole, it has to start from the beginning and is rewarded the value 0.\n",
        "The process continues until it learns from every mistake and reaches the goal. Here is a visual description of the Frozen Lake grid task:\n",
        "\n",
        "![](https://github.com/EgeSarii/Reinforcement-Learning/blob/main/data/FrozenLake.png?raw=1)\n",
        "\n",
        "Note that the ice is slippery, so the agent won't always move in the direction intended by the action. Specifically, there is a 1/3 chance of moving in the direction prescribed by the action and 1/3 to each orthogonal direction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "F6BehbdIP5Hd"
      },
      "outputs": [],
      "source": [
        "# if you don't have gym installed, uncomment and run these lines\n",
        "# Install a pip package in the current Jupyter kernel\n",
        "# import sys\n",
        "# !{sys.executable} -m pip install gym"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "1TQz05J2P5He"
      },
      "outputs": [],
      "source": [
        "import gym\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ATaGEjrtP5He",
        "outputId": "6377ca69-e28e-4a0f-94b3-eb6b51d90934"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_values([EnvSpec(Copy-v0), EnvSpec(RepeatCopy-v0), EnvSpec(ReversedAddition-v0), EnvSpec(ReversedAddition3-v0), EnvSpec(DuplicatedInput-v0), EnvSpec(Reverse-v0), EnvSpec(CartPole-v0), EnvSpec(CartPole-v1), EnvSpec(MountainCar-v0), EnvSpec(MountainCarContinuous-v0), EnvSpec(Pendulum-v0), EnvSpec(Acrobot-v1), EnvSpec(LunarLander-v2), EnvSpec(LunarLanderContinuous-v2), EnvSpec(BipedalWalker-v3), EnvSpec(BipedalWalkerHardcore-v3), EnvSpec(CarRacing-v0), EnvSpec(Blackjack-v0), EnvSpec(KellyCoinflip-v0), EnvSpec(KellyCoinflipGeneralized-v0), EnvSpec(FrozenLake-v0), EnvSpec(FrozenLake8x8-v0), EnvSpec(CliffWalking-v0), EnvSpec(NChain-v0), EnvSpec(Roulette-v0), EnvSpec(Taxi-v3), EnvSpec(GuessingGame-v0), EnvSpec(HotterColder-v0), EnvSpec(Reacher-v2), EnvSpec(Pusher-v2), EnvSpec(Thrower-v2), EnvSpec(Striker-v2), EnvSpec(InvertedPendulum-v2), EnvSpec(InvertedDoublePendulum-v2), EnvSpec(HalfCheetah-v2), EnvSpec(HalfCheetah-v3), EnvSpec(Hopper-v2), EnvSpec(Hopper-v3), EnvSpec(Swimmer-v2), EnvSpec(Swimmer-v3), EnvSpec(Walker2d-v2), EnvSpec(Walker2d-v3), EnvSpec(Ant-v2), EnvSpec(Ant-v3), EnvSpec(Humanoid-v2), EnvSpec(Humanoid-v3), EnvSpec(HumanoidStandup-v2), EnvSpec(FetchSlide-v1), EnvSpec(FetchPickAndPlace-v1), EnvSpec(FetchReach-v1), EnvSpec(FetchPush-v1), EnvSpec(HandReach-v0), EnvSpec(HandManipulateBlockRotateZ-v0), EnvSpec(HandManipulateBlockRotateZTouchSensors-v0), EnvSpec(HandManipulateBlockRotateZTouchSensors-v1), EnvSpec(HandManipulateBlockRotateParallel-v0), EnvSpec(HandManipulateBlockRotateParallelTouchSensors-v0), EnvSpec(HandManipulateBlockRotateParallelTouchSensors-v1), EnvSpec(HandManipulateBlockRotateXYZ-v0), EnvSpec(HandManipulateBlockRotateXYZTouchSensors-v0), EnvSpec(HandManipulateBlockRotateXYZTouchSensors-v1), EnvSpec(HandManipulateBlockFull-v0), EnvSpec(HandManipulateBlock-v0), EnvSpec(HandManipulateBlockTouchSensors-v0), EnvSpec(HandManipulateBlockTouchSensors-v1), EnvSpec(HandManipulateEggRotate-v0), EnvSpec(HandManipulateEggRotateTouchSensors-v0), EnvSpec(HandManipulateEggRotateTouchSensors-v1), EnvSpec(HandManipulateEggFull-v0), EnvSpec(HandManipulateEgg-v0), EnvSpec(HandManipulateEggTouchSensors-v0), EnvSpec(HandManipulateEggTouchSensors-v1), EnvSpec(HandManipulatePenRotate-v0), EnvSpec(HandManipulatePenRotateTouchSensors-v0), EnvSpec(HandManipulatePenRotateTouchSensors-v1), EnvSpec(HandManipulatePenFull-v0), EnvSpec(HandManipulatePen-v0), EnvSpec(HandManipulatePenTouchSensors-v0), EnvSpec(HandManipulatePenTouchSensors-v1), EnvSpec(FetchSlideDense-v1), EnvSpec(FetchPickAndPlaceDense-v1), EnvSpec(FetchReachDense-v1), EnvSpec(FetchPushDense-v1), EnvSpec(HandReachDense-v0), EnvSpec(HandManipulateBlockRotateZDense-v0), EnvSpec(HandManipulateBlockRotateZTouchSensorsDense-v0), EnvSpec(HandManipulateBlockRotateZTouchSensorsDense-v1), EnvSpec(HandManipulateBlockRotateParallelDense-v0), EnvSpec(HandManipulateBlockRotateParallelTouchSensorsDense-v0), EnvSpec(HandManipulateBlockRotateParallelTouchSensorsDense-v1), EnvSpec(HandManipulateBlockRotateXYZDense-v0), EnvSpec(HandManipulateBlockRotateXYZTouchSensorsDense-v0), EnvSpec(HandManipulateBlockRotateXYZTouchSensorsDense-v1), EnvSpec(HandManipulateBlockFullDense-v0), EnvSpec(HandManipulateBlockDense-v0), EnvSpec(HandManipulateBlockTouchSensorsDense-v0), EnvSpec(HandManipulateBlockTouchSensorsDense-v1), EnvSpec(HandManipulateEggRotateDense-v0), EnvSpec(HandManipulateEggRotateTouchSensorsDense-v0), EnvSpec(HandManipulateEggRotateTouchSensorsDense-v1), EnvSpec(HandManipulateEggFullDense-v0), EnvSpec(HandManipulateEggDense-v0), EnvSpec(HandManipulateEggTouchSensorsDense-v0), EnvSpec(HandManipulateEggTouchSensorsDense-v1), EnvSpec(HandManipulatePenRotateDense-v0), EnvSpec(HandManipulatePenRotateTouchSensorsDense-v0), EnvSpec(HandManipulatePenRotateTouchSensorsDense-v1), EnvSpec(HandManipulatePenFullDense-v0), EnvSpec(HandManipulatePenDense-v0), EnvSpec(HandManipulatePenTouchSensorsDense-v0), EnvSpec(HandManipulatePenTouchSensorsDense-v1), EnvSpec(Adventure-v0), EnvSpec(Adventure-v4), EnvSpec(AdventureDeterministic-v0), EnvSpec(AdventureDeterministic-v4), EnvSpec(AdventureNoFrameskip-v0), EnvSpec(AdventureNoFrameskip-v4), EnvSpec(Adventure-ram-v0), EnvSpec(Adventure-ram-v4), EnvSpec(Adventure-ramDeterministic-v0), EnvSpec(Adventure-ramDeterministic-v4), EnvSpec(Adventure-ramNoFrameskip-v0), EnvSpec(Adventure-ramNoFrameskip-v4), EnvSpec(AirRaid-v0), EnvSpec(AirRaid-v4), EnvSpec(AirRaidDeterministic-v0), EnvSpec(AirRaidDeterministic-v4), EnvSpec(AirRaidNoFrameskip-v0), EnvSpec(AirRaidNoFrameskip-v4), EnvSpec(AirRaid-ram-v0), EnvSpec(AirRaid-ram-v4), EnvSpec(AirRaid-ramDeterministic-v0), EnvSpec(AirRaid-ramDeterministic-v4), EnvSpec(AirRaid-ramNoFrameskip-v0), EnvSpec(AirRaid-ramNoFrameskip-v4), EnvSpec(Alien-v0), EnvSpec(Alien-v4), EnvSpec(AlienDeterministic-v0), EnvSpec(AlienDeterministic-v4), EnvSpec(AlienNoFrameskip-v0), EnvSpec(AlienNoFrameskip-v4), EnvSpec(Alien-ram-v0), EnvSpec(Alien-ram-v4), EnvSpec(Alien-ramDeterministic-v0), EnvSpec(Alien-ramDeterministic-v4), EnvSpec(Alien-ramNoFrameskip-v0), EnvSpec(Alien-ramNoFrameskip-v4), EnvSpec(Amidar-v0), EnvSpec(Amidar-v4), EnvSpec(AmidarDeterministic-v0), EnvSpec(AmidarDeterministic-v4), EnvSpec(AmidarNoFrameskip-v0), EnvSpec(AmidarNoFrameskip-v4), EnvSpec(Amidar-ram-v0), EnvSpec(Amidar-ram-v4), EnvSpec(Amidar-ramDeterministic-v0), EnvSpec(Amidar-ramDeterministic-v4), EnvSpec(Amidar-ramNoFrameskip-v0), EnvSpec(Amidar-ramNoFrameskip-v4), EnvSpec(Assault-v0), EnvSpec(Assault-v4), EnvSpec(AssaultDeterministic-v0), EnvSpec(AssaultDeterministic-v4), EnvSpec(AssaultNoFrameskip-v0), EnvSpec(AssaultNoFrameskip-v4), EnvSpec(Assault-ram-v0), EnvSpec(Assault-ram-v4), EnvSpec(Assault-ramDeterministic-v0), EnvSpec(Assault-ramDeterministic-v4), EnvSpec(Assault-ramNoFrameskip-v0), EnvSpec(Assault-ramNoFrameskip-v4), EnvSpec(Asterix-v0), EnvSpec(Asterix-v4), EnvSpec(AsterixDeterministic-v0), EnvSpec(AsterixDeterministic-v4), EnvSpec(AsterixNoFrameskip-v0), EnvSpec(AsterixNoFrameskip-v4), EnvSpec(Asterix-ram-v0), EnvSpec(Asterix-ram-v4), EnvSpec(Asterix-ramDeterministic-v0), EnvSpec(Asterix-ramDeterministic-v4), EnvSpec(Asterix-ramNoFrameskip-v0), EnvSpec(Asterix-ramNoFrameskip-v4), EnvSpec(Asteroids-v0), EnvSpec(Asteroids-v4), EnvSpec(AsteroidsDeterministic-v0), EnvSpec(AsteroidsDeterministic-v4), EnvSpec(AsteroidsNoFrameskip-v0), EnvSpec(AsteroidsNoFrameskip-v4), EnvSpec(Asteroids-ram-v0), EnvSpec(Asteroids-ram-v4), EnvSpec(Asteroids-ramDeterministic-v0), EnvSpec(Asteroids-ramDeterministic-v4), EnvSpec(Asteroids-ramNoFrameskip-v0), EnvSpec(Asteroids-ramNoFrameskip-v4), EnvSpec(Atlantis-v0), EnvSpec(Atlantis-v4), EnvSpec(AtlantisDeterministic-v0), EnvSpec(AtlantisDeterministic-v4), EnvSpec(AtlantisNoFrameskip-v0), EnvSpec(AtlantisNoFrameskip-v4), EnvSpec(Atlantis-ram-v0), EnvSpec(Atlantis-ram-v4), EnvSpec(Atlantis-ramDeterministic-v0), EnvSpec(Atlantis-ramDeterministic-v4), EnvSpec(Atlantis-ramNoFrameskip-v0), EnvSpec(Atlantis-ramNoFrameskip-v4), EnvSpec(BankHeist-v0), EnvSpec(BankHeist-v4), EnvSpec(BankHeistDeterministic-v0), EnvSpec(BankHeistDeterministic-v4), EnvSpec(BankHeistNoFrameskip-v0), EnvSpec(BankHeistNoFrameskip-v4), EnvSpec(BankHeist-ram-v0), EnvSpec(BankHeist-ram-v4), EnvSpec(BankHeist-ramDeterministic-v0), EnvSpec(BankHeist-ramDeterministic-v4), EnvSpec(BankHeist-ramNoFrameskip-v0), EnvSpec(BankHeist-ramNoFrameskip-v4), EnvSpec(BattleZone-v0), EnvSpec(BattleZone-v4), EnvSpec(BattleZoneDeterministic-v0), EnvSpec(BattleZoneDeterministic-v4), EnvSpec(BattleZoneNoFrameskip-v0), EnvSpec(BattleZoneNoFrameskip-v4), EnvSpec(BattleZone-ram-v0), EnvSpec(BattleZone-ram-v4), EnvSpec(BattleZone-ramDeterministic-v0), EnvSpec(BattleZone-ramDeterministic-v4), EnvSpec(BattleZone-ramNoFrameskip-v0), EnvSpec(BattleZone-ramNoFrameskip-v4), EnvSpec(BeamRider-v0), EnvSpec(BeamRider-v4), EnvSpec(BeamRiderDeterministic-v0), EnvSpec(BeamRiderDeterministic-v4), EnvSpec(BeamRiderNoFrameskip-v0), EnvSpec(BeamRiderNoFrameskip-v4), EnvSpec(BeamRider-ram-v0), EnvSpec(BeamRider-ram-v4), EnvSpec(BeamRider-ramDeterministic-v0), EnvSpec(BeamRider-ramDeterministic-v4), EnvSpec(BeamRider-ramNoFrameskip-v0), EnvSpec(BeamRider-ramNoFrameskip-v4), EnvSpec(Berzerk-v0), EnvSpec(Berzerk-v4), EnvSpec(BerzerkDeterministic-v0), EnvSpec(BerzerkDeterministic-v4), EnvSpec(BerzerkNoFrameskip-v0), EnvSpec(BerzerkNoFrameskip-v4), EnvSpec(Berzerk-ram-v0), EnvSpec(Berzerk-ram-v4), EnvSpec(Berzerk-ramDeterministic-v0), EnvSpec(Berzerk-ramDeterministic-v4), EnvSpec(Berzerk-ramNoFrameskip-v0), EnvSpec(Berzerk-ramNoFrameskip-v4), EnvSpec(Bowling-v0), EnvSpec(Bowling-v4), EnvSpec(BowlingDeterministic-v0), EnvSpec(BowlingDeterministic-v4), EnvSpec(BowlingNoFrameskip-v0), EnvSpec(BowlingNoFrameskip-v4), EnvSpec(Bowling-ram-v0), EnvSpec(Bowling-ram-v4), EnvSpec(Bowling-ramDeterministic-v0), EnvSpec(Bowling-ramDeterministic-v4), EnvSpec(Bowling-ramNoFrameskip-v0), EnvSpec(Bowling-ramNoFrameskip-v4), EnvSpec(Boxing-v0), EnvSpec(Boxing-v4), EnvSpec(BoxingDeterministic-v0), EnvSpec(BoxingDeterministic-v4), EnvSpec(BoxingNoFrameskip-v0), EnvSpec(BoxingNoFrameskip-v4), EnvSpec(Boxing-ram-v0), EnvSpec(Boxing-ram-v4), EnvSpec(Boxing-ramDeterministic-v0), EnvSpec(Boxing-ramDeterministic-v4), EnvSpec(Boxing-ramNoFrameskip-v0), EnvSpec(Boxing-ramNoFrameskip-v4), EnvSpec(Breakout-v0), EnvSpec(Breakout-v4), EnvSpec(BreakoutDeterministic-v0), EnvSpec(BreakoutDeterministic-v4), EnvSpec(BreakoutNoFrameskip-v0), EnvSpec(BreakoutNoFrameskip-v4), EnvSpec(Breakout-ram-v0), EnvSpec(Breakout-ram-v4), EnvSpec(Breakout-ramDeterministic-v0), EnvSpec(Breakout-ramDeterministic-v4), EnvSpec(Breakout-ramNoFrameskip-v0), EnvSpec(Breakout-ramNoFrameskip-v4), EnvSpec(Carnival-v0), EnvSpec(Carnival-v4), EnvSpec(CarnivalDeterministic-v0), EnvSpec(CarnivalDeterministic-v4), EnvSpec(CarnivalNoFrameskip-v0), EnvSpec(CarnivalNoFrameskip-v4), EnvSpec(Carnival-ram-v0), EnvSpec(Carnival-ram-v4), EnvSpec(Carnival-ramDeterministic-v0), EnvSpec(Carnival-ramDeterministic-v4), EnvSpec(Carnival-ramNoFrameskip-v0), EnvSpec(Carnival-ramNoFrameskip-v4), EnvSpec(Centipede-v0), EnvSpec(Centipede-v4), EnvSpec(CentipedeDeterministic-v0), EnvSpec(CentipedeDeterministic-v4), EnvSpec(CentipedeNoFrameskip-v0), EnvSpec(CentipedeNoFrameskip-v4), EnvSpec(Centipede-ram-v0), EnvSpec(Centipede-ram-v4), EnvSpec(Centipede-ramDeterministic-v0), EnvSpec(Centipede-ramDeterministic-v4), EnvSpec(Centipede-ramNoFrameskip-v0), EnvSpec(Centipede-ramNoFrameskip-v4), EnvSpec(ChopperCommand-v0), EnvSpec(ChopperCommand-v4), EnvSpec(ChopperCommandDeterministic-v0), EnvSpec(ChopperCommandDeterministic-v4), EnvSpec(ChopperCommandNoFrameskip-v0), EnvSpec(ChopperCommandNoFrameskip-v4), EnvSpec(ChopperCommand-ram-v0), EnvSpec(ChopperCommand-ram-v4), EnvSpec(ChopperCommand-ramDeterministic-v0), EnvSpec(ChopperCommand-ramDeterministic-v4), EnvSpec(ChopperCommand-ramNoFrameskip-v0), EnvSpec(ChopperCommand-ramNoFrameskip-v4), EnvSpec(CrazyClimber-v0), EnvSpec(CrazyClimber-v4), EnvSpec(CrazyClimberDeterministic-v0), EnvSpec(CrazyClimberDeterministic-v4), EnvSpec(CrazyClimberNoFrameskip-v0), EnvSpec(CrazyClimberNoFrameskip-v4), EnvSpec(CrazyClimber-ram-v0), EnvSpec(CrazyClimber-ram-v4), EnvSpec(CrazyClimber-ramDeterministic-v0), EnvSpec(CrazyClimber-ramDeterministic-v4), EnvSpec(CrazyClimber-ramNoFrameskip-v0), EnvSpec(CrazyClimber-ramNoFrameskip-v4), EnvSpec(Defender-v0), EnvSpec(Defender-v4), EnvSpec(DefenderDeterministic-v0), EnvSpec(DefenderDeterministic-v4), EnvSpec(DefenderNoFrameskip-v0), EnvSpec(DefenderNoFrameskip-v4), EnvSpec(Defender-ram-v0), EnvSpec(Defender-ram-v4), EnvSpec(Defender-ramDeterministic-v0), EnvSpec(Defender-ramDeterministic-v4), EnvSpec(Defender-ramNoFrameskip-v0), EnvSpec(Defender-ramNoFrameskip-v4), EnvSpec(DemonAttack-v0), EnvSpec(DemonAttack-v4), EnvSpec(DemonAttackDeterministic-v0), EnvSpec(DemonAttackDeterministic-v4), EnvSpec(DemonAttackNoFrameskip-v0), EnvSpec(DemonAttackNoFrameskip-v4), EnvSpec(DemonAttack-ram-v0), EnvSpec(DemonAttack-ram-v4), EnvSpec(DemonAttack-ramDeterministic-v0), EnvSpec(DemonAttack-ramDeterministic-v4), EnvSpec(DemonAttack-ramNoFrameskip-v0), EnvSpec(DemonAttack-ramNoFrameskip-v4), EnvSpec(DoubleDunk-v0), EnvSpec(DoubleDunk-v4), EnvSpec(DoubleDunkDeterministic-v0), EnvSpec(DoubleDunkDeterministic-v4), EnvSpec(DoubleDunkNoFrameskip-v0), EnvSpec(DoubleDunkNoFrameskip-v4), EnvSpec(DoubleDunk-ram-v0), EnvSpec(DoubleDunk-ram-v4), EnvSpec(DoubleDunk-ramDeterministic-v0), EnvSpec(DoubleDunk-ramDeterministic-v4), EnvSpec(DoubleDunk-ramNoFrameskip-v0), EnvSpec(DoubleDunk-ramNoFrameskip-v4), EnvSpec(ElevatorAction-v0), EnvSpec(ElevatorAction-v4), EnvSpec(ElevatorActionDeterministic-v0), EnvSpec(ElevatorActionDeterministic-v4), EnvSpec(ElevatorActionNoFrameskip-v0), EnvSpec(ElevatorActionNoFrameskip-v4), EnvSpec(ElevatorAction-ram-v0), EnvSpec(ElevatorAction-ram-v4), EnvSpec(ElevatorAction-ramDeterministic-v0), EnvSpec(ElevatorAction-ramDeterministic-v4), EnvSpec(ElevatorAction-ramNoFrameskip-v0), EnvSpec(ElevatorAction-ramNoFrameskip-v4), EnvSpec(Enduro-v0), EnvSpec(Enduro-v4), EnvSpec(EnduroDeterministic-v0), EnvSpec(EnduroDeterministic-v4), EnvSpec(EnduroNoFrameskip-v0), EnvSpec(EnduroNoFrameskip-v4), EnvSpec(Enduro-ram-v0), EnvSpec(Enduro-ram-v4), EnvSpec(Enduro-ramDeterministic-v0), EnvSpec(Enduro-ramDeterministic-v4), EnvSpec(Enduro-ramNoFrameskip-v0), EnvSpec(Enduro-ramNoFrameskip-v4), EnvSpec(FishingDerby-v0), EnvSpec(FishingDerby-v4), EnvSpec(FishingDerbyDeterministic-v0), EnvSpec(FishingDerbyDeterministic-v4), EnvSpec(FishingDerbyNoFrameskip-v0), EnvSpec(FishingDerbyNoFrameskip-v4), EnvSpec(FishingDerby-ram-v0), EnvSpec(FishingDerby-ram-v4), EnvSpec(FishingDerby-ramDeterministic-v0), EnvSpec(FishingDerby-ramDeterministic-v4), EnvSpec(FishingDerby-ramNoFrameskip-v0), EnvSpec(FishingDerby-ramNoFrameskip-v4), EnvSpec(Freeway-v0), EnvSpec(Freeway-v4), EnvSpec(FreewayDeterministic-v0), EnvSpec(FreewayDeterministic-v4), EnvSpec(FreewayNoFrameskip-v0), EnvSpec(FreewayNoFrameskip-v4), EnvSpec(Freeway-ram-v0), EnvSpec(Freeway-ram-v4), EnvSpec(Freeway-ramDeterministic-v0), EnvSpec(Freeway-ramDeterministic-v4), EnvSpec(Freeway-ramNoFrameskip-v0), EnvSpec(Freeway-ramNoFrameskip-v4), EnvSpec(Frostbite-v0), EnvSpec(Frostbite-v4), EnvSpec(FrostbiteDeterministic-v0), EnvSpec(FrostbiteDeterministic-v4), EnvSpec(FrostbiteNoFrameskip-v0), EnvSpec(FrostbiteNoFrameskip-v4), EnvSpec(Frostbite-ram-v0), EnvSpec(Frostbite-ram-v4), EnvSpec(Frostbite-ramDeterministic-v0), EnvSpec(Frostbite-ramDeterministic-v4), EnvSpec(Frostbite-ramNoFrameskip-v0), EnvSpec(Frostbite-ramNoFrameskip-v4), EnvSpec(Gopher-v0), EnvSpec(Gopher-v4), EnvSpec(GopherDeterministic-v0), EnvSpec(GopherDeterministic-v4), EnvSpec(GopherNoFrameskip-v0), EnvSpec(GopherNoFrameskip-v4), EnvSpec(Gopher-ram-v0), EnvSpec(Gopher-ram-v4), EnvSpec(Gopher-ramDeterministic-v0), EnvSpec(Gopher-ramDeterministic-v4), EnvSpec(Gopher-ramNoFrameskip-v0), EnvSpec(Gopher-ramNoFrameskip-v4), EnvSpec(Gravitar-v0), EnvSpec(Gravitar-v4), EnvSpec(GravitarDeterministic-v0), EnvSpec(GravitarDeterministic-v4), EnvSpec(GravitarNoFrameskip-v0), EnvSpec(GravitarNoFrameskip-v4), EnvSpec(Gravitar-ram-v0), EnvSpec(Gravitar-ram-v4), EnvSpec(Gravitar-ramDeterministic-v0), EnvSpec(Gravitar-ramDeterministic-v4), EnvSpec(Gravitar-ramNoFrameskip-v0), EnvSpec(Gravitar-ramNoFrameskip-v4), EnvSpec(Hero-v0), EnvSpec(Hero-v4), EnvSpec(HeroDeterministic-v0), EnvSpec(HeroDeterministic-v4), EnvSpec(HeroNoFrameskip-v0), EnvSpec(HeroNoFrameskip-v4), EnvSpec(Hero-ram-v0), EnvSpec(Hero-ram-v4), EnvSpec(Hero-ramDeterministic-v0), EnvSpec(Hero-ramDeterministic-v4), EnvSpec(Hero-ramNoFrameskip-v0), EnvSpec(Hero-ramNoFrameskip-v4), EnvSpec(IceHockey-v0), EnvSpec(IceHockey-v4), EnvSpec(IceHockeyDeterministic-v0), EnvSpec(IceHockeyDeterministic-v4), EnvSpec(IceHockeyNoFrameskip-v0), EnvSpec(IceHockeyNoFrameskip-v4), EnvSpec(IceHockey-ram-v0), EnvSpec(IceHockey-ram-v4), EnvSpec(IceHockey-ramDeterministic-v0), EnvSpec(IceHockey-ramDeterministic-v4), EnvSpec(IceHockey-ramNoFrameskip-v0), EnvSpec(IceHockey-ramNoFrameskip-v4), EnvSpec(Jamesbond-v0), EnvSpec(Jamesbond-v4), EnvSpec(JamesbondDeterministic-v0), EnvSpec(JamesbondDeterministic-v4), EnvSpec(JamesbondNoFrameskip-v0), EnvSpec(JamesbondNoFrameskip-v4), EnvSpec(Jamesbond-ram-v0), EnvSpec(Jamesbond-ram-v4), EnvSpec(Jamesbond-ramDeterministic-v0), EnvSpec(Jamesbond-ramDeterministic-v4), EnvSpec(Jamesbond-ramNoFrameskip-v0), EnvSpec(Jamesbond-ramNoFrameskip-v4), EnvSpec(JourneyEscape-v0), EnvSpec(JourneyEscape-v4), EnvSpec(JourneyEscapeDeterministic-v0), EnvSpec(JourneyEscapeDeterministic-v4), EnvSpec(JourneyEscapeNoFrameskip-v0), EnvSpec(JourneyEscapeNoFrameskip-v4), EnvSpec(JourneyEscape-ram-v0), EnvSpec(JourneyEscape-ram-v4), EnvSpec(JourneyEscape-ramDeterministic-v0), EnvSpec(JourneyEscape-ramDeterministic-v4), EnvSpec(JourneyEscape-ramNoFrameskip-v0), EnvSpec(JourneyEscape-ramNoFrameskip-v4), EnvSpec(Kangaroo-v0), EnvSpec(Kangaroo-v4), EnvSpec(KangarooDeterministic-v0), EnvSpec(KangarooDeterministic-v4), EnvSpec(KangarooNoFrameskip-v0), EnvSpec(KangarooNoFrameskip-v4), EnvSpec(Kangaroo-ram-v0), EnvSpec(Kangaroo-ram-v4), EnvSpec(Kangaroo-ramDeterministic-v0), EnvSpec(Kangaroo-ramDeterministic-v4), EnvSpec(Kangaroo-ramNoFrameskip-v0), EnvSpec(Kangaroo-ramNoFrameskip-v4), EnvSpec(Krull-v0), EnvSpec(Krull-v4), EnvSpec(KrullDeterministic-v0), EnvSpec(KrullDeterministic-v4), EnvSpec(KrullNoFrameskip-v0), EnvSpec(KrullNoFrameskip-v4), EnvSpec(Krull-ram-v0), EnvSpec(Krull-ram-v4), EnvSpec(Krull-ramDeterministic-v0), EnvSpec(Krull-ramDeterministic-v4), EnvSpec(Krull-ramNoFrameskip-v0), EnvSpec(Krull-ramNoFrameskip-v4), EnvSpec(KungFuMaster-v0), EnvSpec(KungFuMaster-v4), EnvSpec(KungFuMasterDeterministic-v0), EnvSpec(KungFuMasterDeterministic-v4), EnvSpec(KungFuMasterNoFrameskip-v0), EnvSpec(KungFuMasterNoFrameskip-v4), EnvSpec(KungFuMaster-ram-v0), EnvSpec(KungFuMaster-ram-v4), EnvSpec(KungFuMaster-ramDeterministic-v0), EnvSpec(KungFuMaster-ramDeterministic-v4), EnvSpec(KungFuMaster-ramNoFrameskip-v0), EnvSpec(KungFuMaster-ramNoFrameskip-v4), EnvSpec(MontezumaRevenge-v0), EnvSpec(MontezumaRevenge-v4), EnvSpec(MontezumaRevengeDeterministic-v0), EnvSpec(MontezumaRevengeDeterministic-v4), EnvSpec(MontezumaRevengeNoFrameskip-v0), EnvSpec(MontezumaRevengeNoFrameskip-v4), EnvSpec(MontezumaRevenge-ram-v0), EnvSpec(MontezumaRevenge-ram-v4), EnvSpec(MontezumaRevenge-ramDeterministic-v0), EnvSpec(MontezumaRevenge-ramDeterministic-v4), EnvSpec(MontezumaRevenge-ramNoFrameskip-v0), EnvSpec(MontezumaRevenge-ramNoFrameskip-v4), EnvSpec(MsPacman-v0), EnvSpec(MsPacman-v4), EnvSpec(MsPacmanDeterministic-v0), EnvSpec(MsPacmanDeterministic-v4), EnvSpec(MsPacmanNoFrameskip-v0), EnvSpec(MsPacmanNoFrameskip-v4), EnvSpec(MsPacman-ram-v0), EnvSpec(MsPacman-ram-v4), EnvSpec(MsPacman-ramDeterministic-v0), EnvSpec(MsPacman-ramDeterministic-v4), EnvSpec(MsPacman-ramNoFrameskip-v0), EnvSpec(MsPacman-ramNoFrameskip-v4), EnvSpec(NameThisGame-v0), EnvSpec(NameThisGame-v4), EnvSpec(NameThisGameDeterministic-v0), EnvSpec(NameThisGameDeterministic-v4), EnvSpec(NameThisGameNoFrameskip-v0), EnvSpec(NameThisGameNoFrameskip-v4), EnvSpec(NameThisGame-ram-v0), EnvSpec(NameThisGame-ram-v4), EnvSpec(NameThisGame-ramDeterministic-v0), EnvSpec(NameThisGame-ramDeterministic-v4), EnvSpec(NameThisGame-ramNoFrameskip-v0), EnvSpec(NameThisGame-ramNoFrameskip-v4), EnvSpec(Phoenix-v0), EnvSpec(Phoenix-v4), EnvSpec(PhoenixDeterministic-v0), EnvSpec(PhoenixDeterministic-v4), EnvSpec(PhoenixNoFrameskip-v0), EnvSpec(PhoenixNoFrameskip-v4), EnvSpec(Phoenix-ram-v0), EnvSpec(Phoenix-ram-v4), EnvSpec(Phoenix-ramDeterministic-v0), EnvSpec(Phoenix-ramDeterministic-v4), EnvSpec(Phoenix-ramNoFrameskip-v0), EnvSpec(Phoenix-ramNoFrameskip-v4), EnvSpec(Pitfall-v0), EnvSpec(Pitfall-v4), EnvSpec(PitfallDeterministic-v0), EnvSpec(PitfallDeterministic-v4), EnvSpec(PitfallNoFrameskip-v0), EnvSpec(PitfallNoFrameskip-v4), EnvSpec(Pitfall-ram-v0), EnvSpec(Pitfall-ram-v4), EnvSpec(Pitfall-ramDeterministic-v0), EnvSpec(Pitfall-ramDeterministic-v4), EnvSpec(Pitfall-ramNoFrameskip-v0), EnvSpec(Pitfall-ramNoFrameskip-v4), EnvSpec(Pong-v0), EnvSpec(Pong-v4), EnvSpec(PongDeterministic-v0), EnvSpec(PongDeterministic-v4), EnvSpec(PongNoFrameskip-v0), EnvSpec(PongNoFrameskip-v4), EnvSpec(Pong-ram-v0), EnvSpec(Pong-ram-v4), EnvSpec(Pong-ramDeterministic-v0), EnvSpec(Pong-ramDeterministic-v4), EnvSpec(Pong-ramNoFrameskip-v0), EnvSpec(Pong-ramNoFrameskip-v4), EnvSpec(Pooyan-v0), EnvSpec(Pooyan-v4), EnvSpec(PooyanDeterministic-v0), EnvSpec(PooyanDeterministic-v4), EnvSpec(PooyanNoFrameskip-v0), EnvSpec(PooyanNoFrameskip-v4), EnvSpec(Pooyan-ram-v0), EnvSpec(Pooyan-ram-v4), EnvSpec(Pooyan-ramDeterministic-v0), EnvSpec(Pooyan-ramDeterministic-v4), EnvSpec(Pooyan-ramNoFrameskip-v0), EnvSpec(Pooyan-ramNoFrameskip-v4), EnvSpec(PrivateEye-v0), EnvSpec(PrivateEye-v4), EnvSpec(PrivateEyeDeterministic-v0), EnvSpec(PrivateEyeDeterministic-v4), EnvSpec(PrivateEyeNoFrameskip-v0), EnvSpec(PrivateEyeNoFrameskip-v4), EnvSpec(PrivateEye-ram-v0), EnvSpec(PrivateEye-ram-v4), EnvSpec(PrivateEye-ramDeterministic-v0), EnvSpec(PrivateEye-ramDeterministic-v4), EnvSpec(PrivateEye-ramNoFrameskip-v0), EnvSpec(PrivateEye-ramNoFrameskip-v4), EnvSpec(Qbert-v0), EnvSpec(Qbert-v4), EnvSpec(QbertDeterministic-v0), EnvSpec(QbertDeterministic-v4), EnvSpec(QbertNoFrameskip-v0), EnvSpec(QbertNoFrameskip-v4), EnvSpec(Qbert-ram-v0), EnvSpec(Qbert-ram-v4), EnvSpec(Qbert-ramDeterministic-v0), EnvSpec(Qbert-ramDeterministic-v4), EnvSpec(Qbert-ramNoFrameskip-v0), EnvSpec(Qbert-ramNoFrameskip-v4), EnvSpec(Riverraid-v0), EnvSpec(Riverraid-v4), EnvSpec(RiverraidDeterministic-v0), EnvSpec(RiverraidDeterministic-v4), EnvSpec(RiverraidNoFrameskip-v0), EnvSpec(RiverraidNoFrameskip-v4), EnvSpec(Riverraid-ram-v0), EnvSpec(Riverraid-ram-v4), EnvSpec(Riverraid-ramDeterministic-v0), EnvSpec(Riverraid-ramDeterministic-v4), EnvSpec(Riverraid-ramNoFrameskip-v0), EnvSpec(Riverraid-ramNoFrameskip-v4), EnvSpec(RoadRunner-v0), EnvSpec(RoadRunner-v4), EnvSpec(RoadRunnerDeterministic-v0), EnvSpec(RoadRunnerDeterministic-v4), EnvSpec(RoadRunnerNoFrameskip-v0), EnvSpec(RoadRunnerNoFrameskip-v4), EnvSpec(RoadRunner-ram-v0), EnvSpec(RoadRunner-ram-v4), EnvSpec(RoadRunner-ramDeterministic-v0), EnvSpec(RoadRunner-ramDeterministic-v4), EnvSpec(RoadRunner-ramNoFrameskip-v0), EnvSpec(RoadRunner-ramNoFrameskip-v4), EnvSpec(Robotank-v0), EnvSpec(Robotank-v4), EnvSpec(RobotankDeterministic-v0), EnvSpec(RobotankDeterministic-v4), EnvSpec(RobotankNoFrameskip-v0), EnvSpec(RobotankNoFrameskip-v4), EnvSpec(Robotank-ram-v0), EnvSpec(Robotank-ram-v4), EnvSpec(Robotank-ramDeterministic-v0), EnvSpec(Robotank-ramDeterministic-v4), EnvSpec(Robotank-ramNoFrameskip-v0), EnvSpec(Robotank-ramNoFrameskip-v4), EnvSpec(Seaquest-v0), EnvSpec(Seaquest-v4), EnvSpec(SeaquestDeterministic-v0), EnvSpec(SeaquestDeterministic-v4), EnvSpec(SeaquestNoFrameskip-v0), EnvSpec(SeaquestNoFrameskip-v4), EnvSpec(Seaquest-ram-v0), EnvSpec(Seaquest-ram-v4), EnvSpec(Seaquest-ramDeterministic-v0), EnvSpec(Seaquest-ramDeterministic-v4), EnvSpec(Seaquest-ramNoFrameskip-v0), EnvSpec(Seaquest-ramNoFrameskip-v4), EnvSpec(Skiing-v0), EnvSpec(Skiing-v4), EnvSpec(SkiingDeterministic-v0), EnvSpec(SkiingDeterministic-v4), EnvSpec(SkiingNoFrameskip-v0), EnvSpec(SkiingNoFrameskip-v4), EnvSpec(Skiing-ram-v0), EnvSpec(Skiing-ram-v4), EnvSpec(Skiing-ramDeterministic-v0), EnvSpec(Skiing-ramDeterministic-v4), EnvSpec(Skiing-ramNoFrameskip-v0), EnvSpec(Skiing-ramNoFrameskip-v4), EnvSpec(Solaris-v0), EnvSpec(Solaris-v4), EnvSpec(SolarisDeterministic-v0), EnvSpec(SolarisDeterministic-v4), EnvSpec(SolarisNoFrameskip-v0), EnvSpec(SolarisNoFrameskip-v4), EnvSpec(Solaris-ram-v0), EnvSpec(Solaris-ram-v4), EnvSpec(Solaris-ramDeterministic-v0), EnvSpec(Solaris-ramDeterministic-v4), EnvSpec(Solaris-ramNoFrameskip-v0), EnvSpec(Solaris-ramNoFrameskip-v4), EnvSpec(SpaceInvaders-v0), EnvSpec(SpaceInvaders-v4), EnvSpec(SpaceInvadersDeterministic-v0), EnvSpec(SpaceInvadersDeterministic-v4), EnvSpec(SpaceInvadersNoFrameskip-v0), EnvSpec(SpaceInvadersNoFrameskip-v4), EnvSpec(SpaceInvaders-ram-v0), EnvSpec(SpaceInvaders-ram-v4), EnvSpec(SpaceInvaders-ramDeterministic-v0), EnvSpec(SpaceInvaders-ramDeterministic-v4), EnvSpec(SpaceInvaders-ramNoFrameskip-v0), EnvSpec(SpaceInvaders-ramNoFrameskip-v4), EnvSpec(StarGunner-v0), EnvSpec(StarGunner-v4), EnvSpec(StarGunnerDeterministic-v0), EnvSpec(StarGunnerDeterministic-v4), EnvSpec(StarGunnerNoFrameskip-v0), EnvSpec(StarGunnerNoFrameskip-v4), EnvSpec(StarGunner-ram-v0), EnvSpec(StarGunner-ram-v4), EnvSpec(StarGunner-ramDeterministic-v0), EnvSpec(StarGunner-ramDeterministic-v4), EnvSpec(StarGunner-ramNoFrameskip-v0), EnvSpec(StarGunner-ramNoFrameskip-v4), EnvSpec(Tennis-v0), EnvSpec(Tennis-v4), EnvSpec(TennisDeterministic-v0), EnvSpec(TennisDeterministic-v4), EnvSpec(TennisNoFrameskip-v0), EnvSpec(TennisNoFrameskip-v4), EnvSpec(Tennis-ram-v0), EnvSpec(Tennis-ram-v4), EnvSpec(Tennis-ramDeterministic-v0), EnvSpec(Tennis-ramDeterministic-v4), EnvSpec(Tennis-ramNoFrameskip-v0), EnvSpec(Tennis-ramNoFrameskip-v4), EnvSpec(TimePilot-v0), EnvSpec(TimePilot-v4), EnvSpec(TimePilotDeterministic-v0), EnvSpec(TimePilotDeterministic-v4), EnvSpec(TimePilotNoFrameskip-v0), EnvSpec(TimePilotNoFrameskip-v4), EnvSpec(TimePilot-ram-v0), EnvSpec(TimePilot-ram-v4), EnvSpec(TimePilot-ramDeterministic-v0), EnvSpec(TimePilot-ramDeterministic-v4), EnvSpec(TimePilot-ramNoFrameskip-v0), EnvSpec(TimePilot-ramNoFrameskip-v4), EnvSpec(Tutankham-v0), EnvSpec(Tutankham-v4), EnvSpec(TutankhamDeterministic-v0), EnvSpec(TutankhamDeterministic-v4), EnvSpec(TutankhamNoFrameskip-v0), EnvSpec(TutankhamNoFrameskip-v4), EnvSpec(Tutankham-ram-v0), EnvSpec(Tutankham-ram-v4), EnvSpec(Tutankham-ramDeterministic-v0), EnvSpec(Tutankham-ramDeterministic-v4), EnvSpec(Tutankham-ramNoFrameskip-v0), EnvSpec(Tutankham-ramNoFrameskip-v4), EnvSpec(UpNDown-v0), EnvSpec(UpNDown-v4), EnvSpec(UpNDownDeterministic-v0), EnvSpec(UpNDownDeterministic-v4), EnvSpec(UpNDownNoFrameskip-v0), EnvSpec(UpNDownNoFrameskip-v4), EnvSpec(UpNDown-ram-v0), EnvSpec(UpNDown-ram-v4), EnvSpec(UpNDown-ramDeterministic-v0), EnvSpec(UpNDown-ramDeterministic-v4), EnvSpec(UpNDown-ramNoFrameskip-v0), EnvSpec(UpNDown-ramNoFrameskip-v4), EnvSpec(Venture-v0), EnvSpec(Venture-v4), EnvSpec(VentureDeterministic-v0), EnvSpec(VentureDeterministic-v4), EnvSpec(VentureNoFrameskip-v0), EnvSpec(VentureNoFrameskip-v4), EnvSpec(Venture-ram-v0), EnvSpec(Venture-ram-v4), EnvSpec(Venture-ramDeterministic-v0), EnvSpec(Venture-ramDeterministic-v4), EnvSpec(Venture-ramNoFrameskip-v0), EnvSpec(Venture-ramNoFrameskip-v4), EnvSpec(VideoPinball-v0), EnvSpec(VideoPinball-v4), EnvSpec(VideoPinballDeterministic-v0), EnvSpec(VideoPinballDeterministic-v4), EnvSpec(VideoPinballNoFrameskip-v0), EnvSpec(VideoPinballNoFrameskip-v4), EnvSpec(VideoPinball-ram-v0), EnvSpec(VideoPinball-ram-v4), EnvSpec(VideoPinball-ramDeterministic-v0), EnvSpec(VideoPinball-ramDeterministic-v4), EnvSpec(VideoPinball-ramNoFrameskip-v0), EnvSpec(VideoPinball-ramNoFrameskip-v4), EnvSpec(WizardOfWor-v0), EnvSpec(WizardOfWor-v4), EnvSpec(WizardOfWorDeterministic-v0), EnvSpec(WizardOfWorDeterministic-v4), EnvSpec(WizardOfWorNoFrameskip-v0), EnvSpec(WizardOfWorNoFrameskip-v4), EnvSpec(WizardOfWor-ram-v0), EnvSpec(WizardOfWor-ram-v4), EnvSpec(WizardOfWor-ramDeterministic-v0), EnvSpec(WizardOfWor-ramDeterministic-v4), EnvSpec(WizardOfWor-ramNoFrameskip-v0), EnvSpec(WizardOfWor-ramNoFrameskip-v4), EnvSpec(YarsRevenge-v0), EnvSpec(YarsRevenge-v4), EnvSpec(YarsRevengeDeterministic-v0), EnvSpec(YarsRevengeDeterministic-v4), EnvSpec(YarsRevengeNoFrameskip-v0), EnvSpec(YarsRevengeNoFrameskip-v4), EnvSpec(YarsRevenge-ram-v0), EnvSpec(YarsRevenge-ram-v4), EnvSpec(YarsRevenge-ramDeterministic-v0), EnvSpec(YarsRevenge-ramDeterministic-v4), EnvSpec(YarsRevenge-ramNoFrameskip-v0), EnvSpec(YarsRevenge-ramNoFrameskip-v4), EnvSpec(Zaxxon-v0), EnvSpec(Zaxxon-v4), EnvSpec(ZaxxonDeterministic-v0), EnvSpec(ZaxxonDeterministic-v4), EnvSpec(ZaxxonNoFrameskip-v0), EnvSpec(ZaxxonNoFrameskip-v4), EnvSpec(Zaxxon-ram-v0), EnvSpec(Zaxxon-ram-v4), EnvSpec(Zaxxon-ramDeterministic-v0), EnvSpec(Zaxxon-ramDeterministic-v4), EnvSpec(Zaxxon-ramNoFrameskip-v0), EnvSpec(Zaxxon-ramNoFrameskip-v4), EnvSpec(CubeCrash-v0), EnvSpec(CubeCrashSparse-v0), EnvSpec(CubeCrashScreenBecomesBlack-v0), EnvSpec(MemorizeDigits-v0)])\n"
          ]
        }
      ],
      "source": [
        "from gym import envs\n",
        "print(envs.registry.all()) # check if 'FrozenLake-v1' and 'FrozenLake8x8-v1' are among the environments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "ZA3QF3XQP5Hf"
      },
      "source": [
        "In the code provided below, an agent taking random actions is interacting with this environment (i.e., the initial policy is a deterministic random policy)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "_ts1pGQjP5Hf"
      },
      "outputs": [],
      "source": [
        "def run_episodes(environment, n_episodes, policy, display=True):\n",
        "    wins = 0\n",
        "    total_reward = 0\n",
        "    for episode in range(n_episodes):\n",
        "        terminated = False\n",
        "        state = environment.reset()\n",
        "        while not terminated:\n",
        "            # Select an action to perform in a current state\n",
        "            if policy == 'random':\n",
        "                action = environment.action_space.sample()\n",
        "            else:\n",
        "                action = np.argmax(policy[state])\n",
        "\n",
        "            # Perform an action and observe how environment acted in response\n",
        "            next_state, reward, terminated, info = environment.step(action)\n",
        "\n",
        "            # Plot the first episode\n",
        "            if episode==1 and display:\n",
        "                print(\"Action:\")\n",
        "                environment.render() # display current agent state\n",
        "            # Summarize total reward\n",
        "            total_reward += reward\n",
        "            # Update current state\n",
        "            state = next_state\n",
        "            # Calculate number of wins over episodes\n",
        "            if terminated and reward == 1.0:\n",
        "                wins += 1\n",
        "    average_reward = total_reward / n_episodes\n",
        "    return wins, total_reward, average_reward"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32i2b03MP5Hg",
        "outputId": "b859119c-0b06-4d14-b72a-cf0c5a5983d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First episode:\n",
            "Action:\n",
            "  (Left)\n",
            "SFFF\n",
            "\u001b[41mF\u001b[0mHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Action:\n",
            "  (Left)\n",
            "SFFF\n",
            "FHFH\n",
            "\u001b[41mF\u001b[0mFFH\n",
            "HFFG\n",
            "Action:\n",
            "  (Left)\n",
            "SFFF\n",
            "FHFH\n",
            "\u001b[41mF\u001b[0mFFH\n",
            "HFFG\n",
            "Action:\n",
            "  (Down)\n",
            "SFFF\n",
            "FHFH\n",
            "\u001b[41mF\u001b[0mFFH\n",
            "HFFG\n",
            "Action:\n",
            "  (Up)\n",
            "SFFF\n",
            "FHFH\n",
            "F\u001b[41mF\u001b[0mFH\n",
            "HFFG\n",
            "Action:\n",
            "  (Down)\n",
            "SFFF\n",
            "FHFH\n",
            "FF\u001b[41mF\u001b[0mH\n",
            "HFFG\n",
            "Action:\n",
            "  (Left)\n",
            "SFFF\n",
            "FH\u001b[41mF\u001b[0mH\n",
            "FFFH\n",
            "HFFG\n",
            "Action:\n",
            "  (Up)\n",
            "SFFF\n",
            "F\u001b[41mH\u001b[0mFH\n",
            "FFFH\n",
            "HFFG\n",
            "------------------------------------\n",
            "Summary:\n",
            "- number of wins over 5000 episodes = 68\n",
            "- average reward over 5000 episodes = 0.0136\n"
          ]
        }
      ],
      "source": [
        "# Load a Frozen Lake environment\n",
        "env = gym.make('FrozenLake-v0')\n",
        "# Number of episodes to play\n",
        "n_episodes = 5000\n",
        "# First episode plotted as a sample episode\n",
        "print('First episode:')\n",
        "wins, total_reward, average_reward = run_episodes(env, n_episodes, policy=\"random\")\n",
        "print('------------------------------------')\n",
        "print('Summary:')\n",
        "print(f'- number of wins over {n_episodes} episodes = {wins}')\n",
        "print(f'- average reward over {n_episodes} episodes = {average_reward}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "DtzXu-4UP5Hh"
      },
      "source": [
        "**a**) Implement the Iterative Policy Evaluation algorithm as a function to evaluate the given policy. How many iterations does the random policy need to converge?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "LlgXIhReP5Hi"
      },
      "outputs": [],
      "source": [
        "def policy_evaluation(policy, environment, discount_factor=1.0, theta=1e-9, max_iterations=1e9):\n",
        "    # Number of evaluation iterations\n",
        "    evaluation_iterations = 1\n",
        "    # Initialize a value function for each state as zero\n",
        "    V = np.zeros(environment.nS)\n",
        "    # Repeat until change in value is below the threshold\n",
        "    for i in range(int(max_iterations)):\n",
        "        # Initialize a change of value function as zero\n",
        "        delta = 0\n",
        "        # Iterate though each state\n",
        "        for state in range(environment.nS):\n",
        "            # TODO your code here\n",
        "            v= V[state]\n",
        "            # print(\"policy evaluation: v= \", v)\n",
        "            action_values = []\n",
        "            for action, prob_action in enumerate(policy[state]):\n",
        "              state_value = 0\n",
        "              for i in range(len(env.P[state][action])):\n",
        "                prob_next_state, next_state, reward, terminated = env.P[state][action][i]\n",
        "                state_action_value = prob_next_state * (reward + discount_factor *V[next_state])\n",
        "                state_value += state_action_value\n",
        "              action_values.append(prob_action * state_value)\n",
        "            V[state] =sum(action_values)  \n",
        "            # Calculate the absolute change of value function\n",
        "            delta = max(delta, np.abs(V[state] - v))\n",
        "            # Update value function\n",
        "        evaluation_iterations += 1\n",
        "        # Terminate if value change is insignificant\n",
        "        if delta < theta:\n",
        "            print(f'Policy-iteration converged at iteration #{i}.')\n",
        "            return V"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "Ivei5ToTP5Hj"
      },
      "source": [
        "**b**) Using your Policy Evaluation function from (a), implement the Policy iteration algorithm. Run the Policy iteration to obtain the optimal policy for the `FrozenLake-v1` environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "CKa4dI3lP5Hk"
      },
      "outputs": [],
      "source": [
        "def one_step_lookahead(environment, state, V, discount_factor):\n",
        "    action_values = np.zeros(environment.nA)\n",
        "    for action in range(environment.nA):\n",
        "        for probability, next_state, reward, terminated in environment.P[state][action]:\n",
        "            action_values[action] += probability * (reward + discount_factor * V[next_state])\n",
        "    return action_values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "def policy_iteration(environment, discount_factor=1.0, max_iterations=1e9):\n",
        "    # Start with a random policy\n",
        "    # num states x num actions / num actions\n",
        "    policy = np.ones([environment.nS, environment.nA]) / environment.nA\n",
        "    # Initialize counter of evaluated policies\n",
        "    evaluated_policies = 1\n",
        "    # Repeat until convergence or critical number of iterations reached\n",
        "    for i in range(int(max_iterations)):\n",
        "        stable_policy = True\n",
        "        # Evaluate current policy\n",
        "        V = policy_evaluation(policy, environment, discount_factor=discount_factor)\n",
        "        # Go through each state and try to improve actions that were taken (policy Improvement)\n",
        "        for state in range(environment.nS):\n",
        "            # Choose the best action in a current state under current policy\n",
        "            current_action = np.argmax(policy[state])\n",
        "            # Look one step ahead and evaluate if current action is optimal\n",
        "            # We will try every possible action in a current state\n",
        "            action_value = one_step_lookahead(environment, state, V, discount_factor)\n",
        "            # Select a better action\n",
        "            action_values = []\n",
        "            for action in range(env.nA):\n",
        "              state_value =0\n",
        "              for i in range(len(environment.P[state][action])):\n",
        "                prob_next_state, next_state, reward, terminated = env.P[state][action][i]\n",
        "                # print(prob,next_state,reward)\n",
        "                state_action_value =prob_next_state * (reward + (discount_factor* V[next_state]))\n",
        "                # print(state_action_value)\n",
        "                state_value += state_action_value\n",
        "              action_values.append(state_value)\n",
        "            # print(action_values)  \n",
        "            best_action = np.argmax(action_values) \n",
        "            # If action didn't change\n",
        "            if current_action != best_action:\n",
        "                stable_policy = False\n",
        "                # Greedy policy update\n",
        "                policy[state] = np.eye(environment.nA)[best_action]\n",
        "        evaluated_policies += 1\n",
        "        # If the algorithm converged and policy is not changing anymore, then return final policy and value function\n",
        "        if stable_policy:\n",
        "            return policy, V"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "7vOmm2fRP5Hk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Policy-iteration converged at iteration #0.\n",
            "Policy-iteration converged at iteration #0.\n",
            "Policy-iteration converged at iteration #0.\n",
            "Action:\n",
            "  (Left)\n",
            "SFFF\n",
            "\u001b[41mF\u001b[0mHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Action:\n",
            "  (Left)\n",
            "\u001b[41mS\u001b[0mFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Action:\n",
            "  (Left)\n",
            "\u001b[41mS\u001b[0mFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Action:\n",
            "  (Left)\n",
            "SFFF\n",
            "\u001b[41mF\u001b[0mHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Action:\n",
            "  (Left)\n",
            "SFFF\n",
            "\u001b[41mF\u001b[0mHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Action:\n",
            "  (Left)\n",
            "SFFF\n",
            "\u001b[41mF\u001b[0mHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Action:\n",
            "  (Left)\n",
            "\u001b[41mS\u001b[0mFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Action:\n",
            "  (Left)\n",
            "\u001b[41mS\u001b[0mFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Action:\n",
            "  (Left)\n",
            "\u001b[41mS\u001b[0mFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Action:\n",
            "  (Left)\n",
            "\u001b[41mS\u001b[0mFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Action:\n",
            "  (Left)\n",
            "SFFF\n",
            "\u001b[41mF\u001b[0mHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Action:\n",
            "  (Left)\n",
            "\u001b[41mS\u001b[0mFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Action:\n",
            "  (Left)\n",
            "\u001b[41mS\u001b[0mFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Action:\n",
            "  (Left)\n",
            "\u001b[41mS\u001b[0mFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Action:\n",
            "  (Left)\n",
            "\u001b[41mS\u001b[0mFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Action:\n",
            "  (Left)\n",
            "\u001b[41mS\u001b[0mFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Action:\n",
            "  (Left)\n",
            "\u001b[41mS\u001b[0mFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Action:\n",
            "  (Left)\n",
            "\u001b[41mS\u001b[0mFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Action:\n",
            "  (Left)\n",
            "\u001b[41mS\u001b[0mFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Action:\n",
            "  (Left)\n",
            "\u001b[41mS\u001b[0mFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Action:\n",
            "  (Left)\n",
            "SFFF\n",
            "\u001b[41mF\u001b[0mHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Action:\n",
            "  (Left)\n",
            "\u001b[41mS\u001b[0mFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Action:\n",
            "  (Left)\n",
            "\u001b[41mS\u001b[0mFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Action:\n",
            "  (Left)\n",
            "\u001b[41mS\u001b[0mFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Action:\n",
            "  (Left)\n",
            "\u001b[41mS\u001b[0mFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Action:\n",
            "  (Left)\n",
            "\u001b[41mS\u001b[0mFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Action:\n",
            "  (Left)\n",
            "\u001b[41mS\u001b[0mFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Action:\n",
            "  (Left)\n",
            "\u001b[41mS\u001b[0mFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Action:\n",
            "  (Left)\n",
            "\u001b[41mS\u001b[0mFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Action:\n",
            "  (Left)\n",
            "SFFF\n",
            "\u001b[41mF\u001b[0mHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Action:\n",
            "  (Left)\n",
            "SFFF\n",
            "FHFH\n",
            "\u001b[41mF\u001b[0mFFH\n",
            "HFFG\n",
            "Action:\n",
            "  (Up)\n",
            "SFFF\n",
            "\u001b[41mF\u001b[0mHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Action:\n",
            "  (Left)\n",
            "SFFF\n",
            "FHFH\n",
            "\u001b[41mF\u001b[0mFFH\n",
            "HFFG\n",
            "Action:\n",
            "  (Up)\n",
            "SFFF\n",
            "FHFH\n",
            "F\u001b[41mF\u001b[0mFH\n",
            "HFFG\n",
            "Action:\n",
            "  (Down)\n",
            "SFFF\n",
            "FHFH\n",
            "\u001b[41mF\u001b[0mFFH\n",
            "HFFG\n",
            "Action:\n",
            "  (Up)\n",
            "SFFF\n",
            "\u001b[41mF\u001b[0mHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Action:\n",
            "  (Left)\n",
            "SFFF\n",
            "\u001b[41mF\u001b[0mHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Action:\n",
            "  (Left)\n",
            "SFFF\n",
            "FHFH\n",
            "\u001b[41mF\u001b[0mFFH\n",
            "HFFG\n",
            "Action:\n",
            "  (Up)\n",
            "SFFF\n",
            "FHFH\n",
            "F\u001b[41mF\u001b[0mFH\n",
            "HFFG\n",
            "Action:\n",
            "  (Down)\n",
            "SFFF\n",
            "FHFH\n",
            "FFFH\n",
            "H\u001b[41mF\u001b[0mFG\n",
            "Action:\n",
            "  (Right)\n",
            "SFFF\n",
            "FHFH\n",
            "FFFH\n",
            "H\u001b[41mF\u001b[0mFG\n",
            "Action:\n",
            "  (Right)\n",
            "SFFF\n",
            "FHFH\n",
            "F\u001b[41mF\u001b[0mFH\n",
            "HFFG\n",
            "Action:\n",
            "  (Down)\n",
            "SFFF\n",
            "FHFH\n",
            "FFFH\n",
            "H\u001b[41mF\u001b[0mFG\n",
            "Action:\n",
            "  (Right)\n",
            "SFFF\n",
            "FHFH\n",
            "FFFH\n",
            "H\u001b[41mF\u001b[0mFG\n",
            "Action:"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
            "  if __name__ == '__main__':\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  (Right)\n",
            "SFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HF\u001b[41mF\u001b[0mG\n",
            "Action:\n",
            "  (Down)\n",
            "SFFF\n",
            "FHFH\n",
            "FFFH\n",
            "H\u001b[41mF\u001b[0mFG\n",
            "Action:\n",
            "  (Right)\n",
            "SFFF\n",
            "FHFH\n",
            "F\u001b[41mF\u001b[0mFH\n",
            "HFFG\n",
            "Action:\n",
            "  (Down)\n",
            "SFFF\n",
            "FHFH\n",
            "\u001b[41mF\u001b[0mFFH\n",
            "HFFG\n",
            "Action:\n",
            "  (Up)\n",
            "SFFF\n",
            "FHFH\n",
            "\u001b[41mF\u001b[0mFFH\n",
            "HFFG\n",
            "Action:\n",
            "  (Up)\n",
            "SFFF\n",
            "FHFH\n",
            "F\u001b[41mF\u001b[0mFH\n",
            "HFFG\n",
            "Action:\n",
            "  (Down)\n",
            "SFFF\n",
            "FHFH\n",
            "FF\u001b[41mF\u001b[0mH\n",
            "HFFG\n",
            "Action:\n",
            "  (Left)\n",
            "SFFF\n",
            "FHFH\n",
            "F\u001b[41mF\u001b[0mFH\n",
            "HFFG\n",
            "Action:\n",
            "  (Down)\n",
            "SFFF\n",
            "FHFH\n",
            "FFFH\n",
            "H\u001b[41mF\u001b[0mFG\n",
            "Action:\n",
            "  (Right)\n",
            "SFFF\n",
            "FHFH\n",
            "F\u001b[41mF\u001b[0mFH\n",
            "HFFG\n",
            "Action:\n",
            "  (Down)\n",
            "SFFF\n",
            "FHFH\n",
            "FF\u001b[41mF\u001b[0mH\n",
            "HFFG\n",
            "Action:\n",
            "  (Left)\n",
            "SFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HF\u001b[41mF\u001b[0mG\n",
            "Action:\n",
            "  (Down)\n",
            "SFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HF\u001b[41mF\u001b[0mG\n",
            "Action:\n",
            "  (Down)\n",
            "SFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HF\u001b[41mF\u001b[0mG\n",
            "Action:\n",
            "  (Down)\n",
            "SFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFF\u001b[41mG\u001b[0m\n",
            "Policy iteration: number of wins over 1000 episodes = 733\n",
            "Policy iteration: average reward over 1000 episodes = 0.733 \n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Number of episodes to play\n",
        "n_episodes = 1000\n",
        "iteration_name = \"Policy iteration\"\n",
        "iteration_func = policy_iteration\n",
        "# Load a Frozen Lake environment\n",
        "environment = gym.make('FrozenLake-v0')\n",
        "# Search for an optimal policy using policy iteration\n",
        "policy, V = iteration_func(environment.env)\n",
        "# Apply best policy to the real environment\n",
        "wins, total_reward, average_reward = run_episodes(environment, n_episodes, policy)\n",
        "print(f'{iteration_name}: number of wins over {n_episodes} episodes = {wins}')\n",
        "print(f'{iteration_name}: average reward over {n_episodes} episodes = {average_reward} \\n\\n')"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hvq-Ty8dP5Hl",
        "outputId": "cfee5796-ecc0-4b8c-92db-dd932f632469"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "TRKCB9bkP5Hl"
      },
      "source": [
        "**c**) Implement the Value iteration algorithm. Run the algorithm to obtain the optimal policy for the `FrozenLake-v1` environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "JIt4GN-OP5Hl"
      },
      "outputs": [],
      "source": [
        "def value_iteration(environment, discount_factor=1.0, theta=1e-9, max_iterations=1e9):\n",
        "    # Initialize state-value function with zeros for each environment state\n",
        "    V = np.zeros(environment.nS)\n",
        "    for i in range(int(max_iterations)):\n",
        "        # Early stopping condition\n",
        "        delta = 0\n",
        "        # Update each state\n",
        "        for state in range(environment.nS):\n",
        "            # Do a one-step lookahead to calculate state-action values\n",
        "            action_value = one_step_lookahead(environment, state, V, discount_factor)\n",
        "            # Select best action to perform based on the highest state-action value\n",
        "            best_action_value = max(action_value)\n",
        "            # Calculate change in value\n",
        "            delta = max(delta, np.abs(V[state] - best_action_value))\n",
        "            # Update the value function for current state\n",
        "            V[state] = best_action_value\n",
        "            # Check if we can stop\n",
        "        if delta < theta:\n",
        "            print(f'Value-iteration converged at iteration #{i}.')\n",
        "            break\n",
        "\n",
        "    # Create a deterministic policy using the optimal value function\n",
        "    policy = np.zeros([environment.nS, environment.nA])\n",
        "    for state in range(environment.nS):\n",
        "        # One step lookahead to find the best action for this state\n",
        "        action_value = one_step_lookahead(environment, state, V, discount_factor)\n",
        "        # Select best action based on the highest state-action value\n",
        "        best_action = np.argmax(action_value)\n",
        "        # Update the policy to perform a better action at a current state\n",
        "        policy[state, best_action] = 1.0\n",
        "    return policy, V"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Number of episodes to play\n",
        "n_episodes = 1000\n",
        "iteration_name = \"Value iteration\"\n",
        "iteration_func = value_iteration\n",
        "# Load a Frozen Lake environment\n",
        "environment = gym.make('FrozenLake-v0')\n",
        "# Search for an optimal policy using policy iteration\n",
        "policy, V = iteration_func(environment.env)\n",
        "# Apply best policy to the real environment\n",
        "wins, total_reward, average_reward = run_episodes(environment, n_episodes, policy)\n",
        "print(f'{iteration_name}: number of wins over {n_episodes} episodes = {wins}')\n",
        "print(f'{iteration_name}: average reward over {n_episodes} episodes = {average_reward} \\n\\n')"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "UDcy2mS-P5Hm"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "IUT2B5hDP5Hm"
      },
      "source": [
        "**d**) Compare two optimal policies in part (b) and (c). Which seems to converge faster and why?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "13XvXtMiP5Hm"
      },
      "outputs": [],
      "source": [
        "# Number of episodes to play\n",
        "n_episodes = 5000\n",
        "# Functions to find best policy\n",
        "solvers = [('Policy Iteration', policy_iteration),\n",
        "           ('Value Iteration', value_iteration)]\n",
        "for iteration_name, iteration_func in solvers:\n",
        "    # Load a Frozen Lake environment\n",
        "    environment = gym.make('FrozenLake-v0')\n",
        "    # Search for an optimal policy using policy iteration\n",
        "    policy, V = iteration_func(environment.env)\n",
        "    # Apply best policy to the real environment\n",
        "    wins, total_reward, average_reward = run_episodes(environment, n_episodes, policy)\n",
        "    print(f'{iteration_name} :: number of wins over {n_episodes} episodes = {wins}')\n",
        "    print(f'{iteration_name} :: average reward over {n_episodes} episodes = {average_reward} \\n\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "DZV8A6dCP5Hm"
      },
      "source": [
        "**e**) Run the Policy Iteration and the Value Iteration algorithms on a bigger environment, FrozenLake8x8-v1. Compare the convergence speed of algorithms for both environments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "vCvJ1Wh5P5Hn"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "vU5HGGdEP5Hn"
      },
      "source": [
        "---\n",
        "#### **2. Gambler's problem**\n",
        "\n",
        "*(4 x 1.25 points)*\n",
        "\n",
        "Consider an agent placing bets on the outcomes of a sequence of coin flips. It the coin toss results in `heads`, the gambler's return is equal to the bet he placed, if the outcome is `tails`, the opposite happens and the gambler looses the bet. The coin lands on heads 40% of the time. The game continues until the gambler has either lost all his capital or reaches his goal of earning $100$.\n",
        "\n",
        "**Problem summary:**\n",
        "- Undiscounted, finite, episodic MDP: $\\gamma=1$ and there is a terminal state\n",
        "- State: gambler's capital $s \\in \\{ 0, 1, 2, ..., 100 \\}$\n",
        "- Actions: the bet $a = \\{ 0, 1, ..., \\mathrm{min}(s, 100-s)\\}$\n",
        "- Policy: maps the current capital available to how much the agent should bet\n",
        "- Terminal states: capital=0 or capital=100\n",
        "- Reward: 0 for all states, except when the goal is reached (capital=100), where it is +1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "EuIYz178P5Hn"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "xUdGgItWP5Hn"
      },
      "outputs": [],
      "source": [
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "lyMNqsYfP5Hn"
      },
      "outputs": [],
      "source": [
        "goal = 100\n",
        "states = np.arange(goal + 1)\n",
        "\n",
        "p_head = 0.4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "hzCrladKP5Ho"
      },
      "source": [
        "**a**) The state-value function gives the probability of winning from each state. Perform value iteration and plot the value of each state in different iterations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "3Oy84x6HP5Ho"
      },
      "outputs": [],
      "source": [
        "# initial values\n",
        "state_value = np.zeros(goal + 1)\n",
        "state_value[goal] = 1.0\n",
        "sweeps_history = []\n",
        "\n",
        "# value iteration\n",
        "while True:\n",
        "    old_state_value = state_value.copy()\n",
        "    sweeps_history.append(old_state_value)\n",
        "\n",
        "    for state in states[1:goal]:\n",
        "        # get possilbe actions for current state\n",
        "        actions = range(0, min(state, (100 - state)+1))\n",
        "        action_returns = []\n",
        "        for action in actions:\n",
        "            returns = [(0.4 * state_value[state+action]) + (0.6 * state_value[state+action] )]\n",
        "            action_returns.append(returns)\n",
        "        new_value = max (actions)\n",
        "        state_value[state] = new_value\n",
        "    delta = abs(state_value - old_state_value).max()\n",
        "    if delta < 1e-9:\n",
        "        sweeps_history.append(state_value)\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Value estimates')"
            ]
          },
          "metadata": {},
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.figure(figsize=(10, 5))\n",
        "for sweep, state_value in enumerate(sweeps_history):\n",
        "    plt.plot(state_value, label='sweep {}'.format(sweep))\n",
        "plt.xlabel('Capital')\n",
        "plt.ylabel('Value estimates')"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "KbUND-VlP5Ho",
        "outputId": "857804fe-5b0e-4e0d-8ee4-ffecf03ef00c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        }
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "Ovgi_AL2P5Hp"
      },
      "source": [
        "**b**) Compute and plot the optimal policy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "fzWGKY6cP5Hp"
      },
      "outputs": [],
      "source": [
        "# compute the optimal policy\n",
        "policy = np.zeros(goal + 1)\n",
        "for state in states[1:goal]:\n",
        "    # actions =\n",
        "    action_returns = []\n",
        "    for action in actions:\n",
        "        # returns =\n",
        "        action_returns.append(returns)\n",
        "    policy[state] = actions[np.argmax(np.round(action_returns[1:], 5)) + 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(states, policy)\n",
        "plt.xlabel('Capital')\n",
        "plt.ylabel('Final policy')"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "v_9XgaBEP5Hp"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "bosAfVokP5Hp"
      },
      "source": [
        "**c**) Re-using your value iteration code provided above, plot the results obtained if $p_{h}=0.25$ and $p_{h}=0.62$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "5-FHwTCBP5Hq"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "ws0-XQBfP5Hq"
      },
      "source": [
        "**d**) Compute and plot the corresponding optimal policies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "qSXj9RU9P5Hq"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "name": "3-DynamicProgramming-assignments.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}