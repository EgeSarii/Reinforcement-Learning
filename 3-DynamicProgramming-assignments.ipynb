{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EgeSarii/Reinforcement-Learning/blob/main/3-DynamicProgramming-assignments.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "C0tJn-yZP5HY"
      },
      "source": [
        "## Reinforcement Learning 3: *Dynamic Programming*\n",
        "\n",
        "**Assignment:** hand-in before 21/02/2022"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "JcS8BtkXP5Hc"
      },
      "source": [
        "#### **1. Frozen Lake**\n",
        "\n",
        "*(5 x 1 points)*\n",
        "\n",
        "The Frozen Lake environment is a 4×4 grid which contain four possible areas  — Safe (S), Frozen (F), Hole (H) and Goal (G). The agent moves around the grid until it reaches the goal or the hole. The agent in the environment has four possible moves — Up, Down, Left and Right. If it falls into the hole, it has to start from the beginning and is rewarded the value 0.\n",
        "The process continues until it learns from every mistake and reaches the goal. Here is a visual description of the Frozen Lake grid task:\n",
        "\n",
        "![](https://github.com/EgeSarii/Reinforcement-Learning/blob/main/data/FrozenLake.png?raw=1)\n",
        "\n",
        "Note that the ice is slippery, so the agent won't always move in the direction intended by the action. Specifically, there is a 1/3 chance of moving in the direction prescribed by the action and 1/3 to each orthogonal direction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "F6BehbdIP5Hd"
      },
      "outputs": [],
      "source": [
        "# if you don't have gym installed, uncomment and run these lines\n",
        "# Install a pip package in the current Jupyter kernel\n",
        "# import sys\n",
        "# !{sys.executable} -m pip install gym"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "1TQz05J2P5He"
      },
      "outputs": [],
      "source": [
        "import gym\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ATaGEjrtP5He",
        "outputId": "6377ca69-e28e-4a0f-94b3-eb6b51d90934"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_values([EnvSpec(Copy-v0), EnvSpec(RepeatCopy-v0), EnvSpec(ReversedAddition-v0), EnvSpec(ReversedAddition3-v0), EnvSpec(DuplicatedInput-v0), EnvSpec(Reverse-v0), EnvSpec(CartPole-v0), EnvSpec(CartPole-v1), EnvSpec(MountainCar-v0), EnvSpec(MountainCarContinuous-v0), EnvSpec(Pendulum-v0), EnvSpec(Acrobot-v1), EnvSpec(LunarLander-v2), EnvSpec(LunarLanderContinuous-v2), EnvSpec(BipedalWalker-v3), EnvSpec(BipedalWalkerHardcore-v3), EnvSpec(CarRacing-v0), EnvSpec(Blackjack-v0), EnvSpec(KellyCoinflip-v0), EnvSpec(KellyCoinflipGeneralized-v0), EnvSpec(FrozenLake-v0), EnvSpec(FrozenLake8x8-v0), EnvSpec(CliffWalking-v0), EnvSpec(NChain-v0), EnvSpec(Roulette-v0), EnvSpec(Taxi-v3), EnvSpec(GuessingGame-v0), EnvSpec(HotterColder-v0), EnvSpec(Reacher-v2), EnvSpec(Pusher-v2), EnvSpec(Thrower-v2), EnvSpec(Striker-v2), EnvSpec(InvertedPendulum-v2), EnvSpec(InvertedDoublePendulum-v2), EnvSpec(HalfCheetah-v2), EnvSpec(HalfCheetah-v3), EnvSpec(Hopper-v2), EnvSpec(Hopper-v3), EnvSpec(Swimmer-v2), EnvSpec(Swimmer-v3), EnvSpec(Walker2d-v2), EnvSpec(Walker2d-v3), EnvSpec(Ant-v2), EnvSpec(Ant-v3), EnvSpec(Humanoid-v2), EnvSpec(Humanoid-v3), EnvSpec(HumanoidStandup-v2), EnvSpec(FetchSlide-v1), EnvSpec(FetchPickAndPlace-v1), EnvSpec(FetchReach-v1), EnvSpec(FetchPush-v1), EnvSpec(HandReach-v0), EnvSpec(HandManipulateBlockRotateZ-v0), EnvSpec(HandManipulateBlockRotateZTouchSensors-v0), EnvSpec(HandManipulateBlockRotateZTouchSensors-v1), EnvSpec(HandManipulateBlockRotateParallel-v0), EnvSpec(HandManipulateBlockRotateParallelTouchSensors-v0), EnvSpec(HandManipulateBlockRotateParallelTouchSensors-v1), EnvSpec(HandManipulateBlockRotateXYZ-v0), EnvSpec(HandManipulateBlockRotateXYZTouchSensors-v0), EnvSpec(HandManipulateBlockRotateXYZTouchSensors-v1), EnvSpec(HandManipulateBlockFull-v0), EnvSpec(HandManipulateBlock-v0), EnvSpec(HandManipulateBlockTouchSensors-v0), EnvSpec(HandManipulateBlockTouchSensors-v1), EnvSpec(HandManipulateEggRotate-v0), EnvSpec(HandManipulateEggRotateTouchSensors-v0), EnvSpec(HandManipulateEggRotateTouchSensors-v1), EnvSpec(HandManipulateEggFull-v0), EnvSpec(HandManipulateEgg-v0), EnvSpec(HandManipulateEggTouchSensors-v0), EnvSpec(HandManipulateEggTouchSensors-v1), EnvSpec(HandManipulatePenRotate-v0), EnvSpec(HandManipulatePenRotateTouchSensors-v0), EnvSpec(HandManipulatePenRotateTouchSensors-v1), EnvSpec(HandManipulatePenFull-v0), EnvSpec(HandManipulatePen-v0), EnvSpec(HandManipulatePenTouchSensors-v0), EnvSpec(HandManipulatePenTouchSensors-v1), EnvSpec(FetchSlideDense-v1), EnvSpec(FetchPickAndPlaceDense-v1), EnvSpec(FetchReachDense-v1), EnvSpec(FetchPushDense-v1), EnvSpec(HandReachDense-v0), EnvSpec(HandManipulateBlockRotateZDense-v0), EnvSpec(HandManipulateBlockRotateZTouchSensorsDense-v0), EnvSpec(HandManipulateBlockRotateZTouchSensorsDense-v1), EnvSpec(HandManipulateBlockRotateParallelDense-v0), EnvSpec(HandManipulateBlockRotateParallelTouchSensorsDense-v0), EnvSpec(HandManipulateBlockRotateParallelTouchSensorsDense-v1), EnvSpec(HandManipulateBlockRotateXYZDense-v0), EnvSpec(HandManipulateBlockRotateXYZTouchSensorsDense-v0), EnvSpec(HandManipulateBlockRotateXYZTouchSensorsDense-v1), EnvSpec(HandManipulateBlockFullDense-v0), EnvSpec(HandManipulateBlockDense-v0), EnvSpec(HandManipulateBlockTouchSensorsDense-v0), EnvSpec(HandManipulateBlockTouchSensorsDense-v1), EnvSpec(HandManipulateEggRotateDense-v0), EnvSpec(HandManipulateEggRotateTouchSensorsDense-v0), EnvSpec(HandManipulateEggRotateTouchSensorsDense-v1), EnvSpec(HandManipulateEggFullDense-v0), EnvSpec(HandManipulateEggDense-v0), EnvSpec(HandManipulateEggTouchSensorsDense-v0), EnvSpec(HandManipulateEggTouchSensorsDense-v1), EnvSpec(HandManipulatePenRotateDense-v0), EnvSpec(HandManipulatePenRotateTouchSensorsDense-v0), EnvSpec(HandManipulatePenRotateTouchSensorsDense-v1), EnvSpec(HandManipulatePenFullDense-v0), EnvSpec(HandManipulatePenDense-v0), EnvSpec(HandManipulatePenTouchSensorsDense-v0), EnvSpec(HandManipulatePenTouchSensorsDense-v1), EnvSpec(Adventure-v0), EnvSpec(Adventure-v4), EnvSpec(AdventureDeterministic-v0), EnvSpec(AdventureDeterministic-v4), EnvSpec(AdventureNoFrameskip-v0), EnvSpec(AdventureNoFrameskip-v4), EnvSpec(Adventure-ram-v0), EnvSpec(Adventure-ram-v4), EnvSpec(Adventure-ramDeterministic-v0), EnvSpec(Adventure-ramDeterministic-v4), EnvSpec(Adventure-ramNoFrameskip-v0), EnvSpec(Adventure-ramNoFrameskip-v4), EnvSpec(AirRaid-v0), EnvSpec(AirRaid-v4), EnvSpec(AirRaidDeterministic-v0), EnvSpec(AirRaidDeterministic-v4), EnvSpec(AirRaidNoFrameskip-v0), EnvSpec(AirRaidNoFrameskip-v4), EnvSpec(AirRaid-ram-v0), EnvSpec(AirRaid-ram-v4), EnvSpec(AirRaid-ramDeterministic-v0), EnvSpec(AirRaid-ramDeterministic-v4), EnvSpec(AirRaid-ramNoFrameskip-v0), EnvSpec(AirRaid-ramNoFrameskip-v4), EnvSpec(Alien-v0), EnvSpec(Alien-v4), EnvSpec(AlienDeterministic-v0), EnvSpec(AlienDeterministic-v4), EnvSpec(AlienNoFrameskip-v0), EnvSpec(AlienNoFrameskip-v4), EnvSpec(Alien-ram-v0), EnvSpec(Alien-ram-v4), EnvSpec(Alien-ramDeterministic-v0), EnvSpec(Alien-ramDeterministic-v4), EnvSpec(Alien-ramNoFrameskip-v0), EnvSpec(Alien-ramNoFrameskip-v4), EnvSpec(Amidar-v0), EnvSpec(Amidar-v4), EnvSpec(AmidarDeterministic-v0), EnvSpec(AmidarDeterministic-v4), EnvSpec(AmidarNoFrameskip-v0), EnvSpec(AmidarNoFrameskip-v4), EnvSpec(Amidar-ram-v0), EnvSpec(Amidar-ram-v4), EnvSpec(Amidar-ramDeterministic-v0), EnvSpec(Amidar-ramDeterministic-v4), EnvSpec(Amidar-ramNoFrameskip-v0), EnvSpec(Amidar-ramNoFrameskip-v4), EnvSpec(Assault-v0), EnvSpec(Assault-v4), EnvSpec(AssaultDeterministic-v0), EnvSpec(AssaultDeterministic-v4), EnvSpec(AssaultNoFrameskip-v0), EnvSpec(AssaultNoFrameskip-v4), EnvSpec(Assault-ram-v0), EnvSpec(Assault-ram-v4), EnvSpec(Assault-ramDeterministic-v0), EnvSpec(Assault-ramDeterministic-v4), EnvSpec(Assault-ramNoFrameskip-v0), EnvSpec(Assault-ramNoFrameskip-v4), EnvSpec(Asterix-v0), EnvSpec(Asterix-v4), EnvSpec(AsterixDeterministic-v0), EnvSpec(AsterixDeterministic-v4), EnvSpec(AsterixNoFrameskip-v0), EnvSpec(AsterixNoFrameskip-v4), EnvSpec(Asterix-ram-v0), EnvSpec(Asterix-ram-v4), EnvSpec(Asterix-ramDeterministic-v0), EnvSpec(Asterix-ramDeterministic-v4), EnvSpec(Asterix-ramNoFrameskip-v0), EnvSpec(Asterix-ramNoFrameskip-v4), EnvSpec(Asteroids-v0), EnvSpec(Asteroids-v4), EnvSpec(AsteroidsDeterministic-v0), EnvSpec(AsteroidsDeterministic-v4), EnvSpec(AsteroidsNoFrameskip-v0), EnvSpec(AsteroidsNoFrameskip-v4), EnvSpec(Asteroids-ram-v0), EnvSpec(Asteroids-ram-v4), EnvSpec(Asteroids-ramDeterministic-v0), EnvSpec(Asteroids-ramDeterministic-v4), EnvSpec(Asteroids-ramNoFrameskip-v0), EnvSpec(Asteroids-ramNoFrameskip-v4), EnvSpec(Atlantis-v0), EnvSpec(Atlantis-v4), EnvSpec(AtlantisDeterministic-v0), EnvSpec(AtlantisDeterministic-v4), EnvSpec(AtlantisNoFrameskip-v0), EnvSpec(AtlantisNoFrameskip-v4), EnvSpec(Atlantis-ram-v0), EnvSpec(Atlantis-ram-v4), EnvSpec(Atlantis-ramDeterministic-v0), EnvSpec(Atlantis-ramDeterministic-v4), EnvSpec(Atlantis-ramNoFrameskip-v0), EnvSpec(Atlantis-ramNoFrameskip-v4), EnvSpec(BankHeist-v0), EnvSpec(BankHeist-v4), EnvSpec(BankHeistDeterministic-v0), EnvSpec(BankHeistDeterministic-v4), EnvSpec(BankHeistNoFrameskip-v0), EnvSpec(BankHeistNoFrameskip-v4), EnvSpec(BankHeist-ram-v0), EnvSpec(BankHeist-ram-v4), EnvSpec(BankHeist-ramDeterministic-v0), EnvSpec(BankHeist-ramDeterministic-v4), EnvSpec(BankHeist-ramNoFrameskip-v0), EnvSpec(BankHeist-ramNoFrameskip-v4), EnvSpec(BattleZone-v0), EnvSpec(BattleZone-v4), EnvSpec(BattleZoneDeterministic-v0), EnvSpec(BattleZoneDeterministic-v4), EnvSpec(BattleZoneNoFrameskip-v0), EnvSpec(BattleZoneNoFrameskip-v4), EnvSpec(BattleZone-ram-v0), EnvSpec(BattleZone-ram-v4), EnvSpec(BattleZone-ramDeterministic-v0), EnvSpec(BattleZone-ramDeterministic-v4), EnvSpec(BattleZone-ramNoFrameskip-v0), EnvSpec(BattleZone-ramNoFrameskip-v4), EnvSpec(BeamRider-v0), EnvSpec(BeamRider-v4), EnvSpec(BeamRiderDeterministic-v0), EnvSpec(BeamRiderDeterministic-v4), EnvSpec(BeamRiderNoFrameskip-v0), EnvSpec(BeamRiderNoFrameskip-v4), EnvSpec(BeamRider-ram-v0), EnvSpec(BeamRider-ram-v4), EnvSpec(BeamRider-ramDeterministic-v0), EnvSpec(BeamRider-ramDeterministic-v4), EnvSpec(BeamRider-ramNoFrameskip-v0), EnvSpec(BeamRider-ramNoFrameskip-v4), EnvSpec(Berzerk-v0), EnvSpec(Berzerk-v4), EnvSpec(BerzerkDeterministic-v0), EnvSpec(BerzerkDeterministic-v4), EnvSpec(BerzerkNoFrameskip-v0), EnvSpec(BerzerkNoFrameskip-v4), EnvSpec(Berzerk-ram-v0), EnvSpec(Berzerk-ram-v4), EnvSpec(Berzerk-ramDeterministic-v0), EnvSpec(Berzerk-ramDeterministic-v4), EnvSpec(Berzerk-ramNoFrameskip-v0), EnvSpec(Berzerk-ramNoFrameskip-v4), EnvSpec(Bowling-v0), EnvSpec(Bowling-v4), EnvSpec(BowlingDeterministic-v0), EnvSpec(BowlingDeterministic-v4), EnvSpec(BowlingNoFrameskip-v0), EnvSpec(BowlingNoFrameskip-v4), EnvSpec(Bowling-ram-v0), EnvSpec(Bowling-ram-v4), EnvSpec(Bowling-ramDeterministic-v0), EnvSpec(Bowling-ramDeterministic-v4), EnvSpec(Bowling-ramNoFrameskip-v0), EnvSpec(Bowling-ramNoFrameskip-v4), EnvSpec(Boxing-v0), EnvSpec(Boxing-v4), EnvSpec(BoxingDeterministic-v0), EnvSpec(BoxingDeterministic-v4), EnvSpec(BoxingNoFrameskip-v0), EnvSpec(BoxingNoFrameskip-v4), EnvSpec(Boxing-ram-v0), EnvSpec(Boxing-ram-v4), EnvSpec(Boxing-ramDeterministic-v0), EnvSpec(Boxing-ramDeterministic-v4), EnvSpec(Boxing-ramNoFrameskip-v0), EnvSpec(Boxing-ramNoFrameskip-v4), EnvSpec(Breakout-v0), EnvSpec(Breakout-v4), EnvSpec(BreakoutDeterministic-v0), EnvSpec(BreakoutDeterministic-v4), EnvSpec(BreakoutNoFrameskip-v0), EnvSpec(BreakoutNoFrameskip-v4), EnvSpec(Breakout-ram-v0), EnvSpec(Breakout-ram-v4), EnvSpec(Breakout-ramDeterministic-v0), EnvSpec(Breakout-ramDeterministic-v4), EnvSpec(Breakout-ramNoFrameskip-v0), EnvSpec(Breakout-ramNoFrameskip-v4), EnvSpec(Carnival-v0), EnvSpec(Carnival-v4), EnvSpec(CarnivalDeterministic-v0), EnvSpec(CarnivalDeterministic-v4), EnvSpec(CarnivalNoFrameskip-v0), EnvSpec(CarnivalNoFrameskip-v4), EnvSpec(Carnival-ram-v0), EnvSpec(Carnival-ram-v4), EnvSpec(Carnival-ramDeterministic-v0), EnvSpec(Carnival-ramDeterministic-v4), EnvSpec(Carnival-ramNoFrameskip-v0), EnvSpec(Carnival-ramNoFrameskip-v4), EnvSpec(Centipede-v0), EnvSpec(Centipede-v4), EnvSpec(CentipedeDeterministic-v0), EnvSpec(CentipedeDeterministic-v4), EnvSpec(CentipedeNoFrameskip-v0), EnvSpec(CentipedeNoFrameskip-v4), EnvSpec(Centipede-ram-v0), EnvSpec(Centipede-ram-v4), EnvSpec(Centipede-ramDeterministic-v0), EnvSpec(Centipede-ramDeterministic-v4), EnvSpec(Centipede-ramNoFrameskip-v0), EnvSpec(Centipede-ramNoFrameskip-v4), EnvSpec(ChopperCommand-v0), EnvSpec(ChopperCommand-v4), EnvSpec(ChopperCommandDeterministic-v0), EnvSpec(ChopperCommandDeterministic-v4), EnvSpec(ChopperCommandNoFrameskip-v0), EnvSpec(ChopperCommandNoFrameskip-v4), EnvSpec(ChopperCommand-ram-v0), EnvSpec(ChopperCommand-ram-v4), EnvSpec(ChopperCommand-ramDeterministic-v0), EnvSpec(ChopperCommand-ramDeterministic-v4), EnvSpec(ChopperCommand-ramNoFrameskip-v0), EnvSpec(ChopperCommand-ramNoFrameskip-v4), EnvSpec(CrazyClimber-v0), EnvSpec(CrazyClimber-v4), EnvSpec(CrazyClimberDeterministic-v0), EnvSpec(CrazyClimberDeterministic-v4), EnvSpec(CrazyClimberNoFrameskip-v0), EnvSpec(CrazyClimberNoFrameskip-v4), EnvSpec(CrazyClimber-ram-v0), EnvSpec(CrazyClimber-ram-v4), EnvSpec(CrazyClimber-ramDeterministic-v0), EnvSpec(CrazyClimber-ramDeterministic-v4), EnvSpec(CrazyClimber-ramNoFrameskip-v0), EnvSpec(CrazyClimber-ramNoFrameskip-v4), EnvSpec(Defender-v0), EnvSpec(Defender-v4), EnvSpec(DefenderDeterministic-v0), EnvSpec(DefenderDeterministic-v4), EnvSpec(DefenderNoFrameskip-v0), EnvSpec(DefenderNoFrameskip-v4), EnvSpec(Defender-ram-v0), EnvSpec(Defender-ram-v4), EnvSpec(Defender-ramDeterministic-v0), EnvSpec(Defender-ramDeterministic-v4), EnvSpec(Defender-ramNoFrameskip-v0), EnvSpec(Defender-ramNoFrameskip-v4), EnvSpec(DemonAttack-v0), EnvSpec(DemonAttack-v4), EnvSpec(DemonAttackDeterministic-v0), EnvSpec(DemonAttackDeterministic-v4), EnvSpec(DemonAttackNoFrameskip-v0), EnvSpec(DemonAttackNoFrameskip-v4), EnvSpec(DemonAttack-ram-v0), EnvSpec(DemonAttack-ram-v4), EnvSpec(DemonAttack-ramDeterministic-v0), EnvSpec(DemonAttack-ramDeterministic-v4), EnvSpec(DemonAttack-ramNoFrameskip-v0), EnvSpec(DemonAttack-ramNoFrameskip-v4), EnvSpec(DoubleDunk-v0), EnvSpec(DoubleDunk-v4), EnvSpec(DoubleDunkDeterministic-v0), EnvSpec(DoubleDunkDeterministic-v4), EnvSpec(DoubleDunkNoFrameskip-v0), EnvSpec(DoubleDunkNoFrameskip-v4), EnvSpec(DoubleDunk-ram-v0), EnvSpec(DoubleDunk-ram-v4), EnvSpec(DoubleDunk-ramDeterministic-v0), EnvSpec(DoubleDunk-ramDeterministic-v4), EnvSpec(DoubleDunk-ramNoFrameskip-v0), EnvSpec(DoubleDunk-ramNoFrameskip-v4), EnvSpec(ElevatorAction-v0), EnvSpec(ElevatorAction-v4), EnvSpec(ElevatorActionDeterministic-v0), EnvSpec(ElevatorActionDeterministic-v4), EnvSpec(ElevatorActionNoFrameskip-v0), EnvSpec(ElevatorActionNoFrameskip-v4), EnvSpec(ElevatorAction-ram-v0), EnvSpec(ElevatorAction-ram-v4), EnvSpec(ElevatorAction-ramDeterministic-v0), EnvSpec(ElevatorAction-ramDeterministic-v4), EnvSpec(ElevatorAction-ramNoFrameskip-v0), EnvSpec(ElevatorAction-ramNoFrameskip-v4), EnvSpec(Enduro-v0), EnvSpec(Enduro-v4), EnvSpec(EnduroDeterministic-v0), EnvSpec(EnduroDeterministic-v4), EnvSpec(EnduroNoFrameskip-v0), EnvSpec(EnduroNoFrameskip-v4), EnvSpec(Enduro-ram-v0), EnvSpec(Enduro-ram-v4), EnvSpec(Enduro-ramDeterministic-v0), EnvSpec(Enduro-ramDeterministic-v4), EnvSpec(Enduro-ramNoFrameskip-v0), EnvSpec(Enduro-ramNoFrameskip-v4), EnvSpec(FishingDerby-v0), EnvSpec(FishingDerby-v4), EnvSpec(FishingDerbyDeterministic-v0), EnvSpec(FishingDerbyDeterministic-v4), EnvSpec(FishingDerbyNoFrameskip-v0), EnvSpec(FishingDerbyNoFrameskip-v4), EnvSpec(FishingDerby-ram-v0), EnvSpec(FishingDerby-ram-v4), EnvSpec(FishingDerby-ramDeterministic-v0), EnvSpec(FishingDerby-ramDeterministic-v4), EnvSpec(FishingDerby-ramNoFrameskip-v0), EnvSpec(FishingDerby-ramNoFrameskip-v4), EnvSpec(Freeway-v0), EnvSpec(Freeway-v4), EnvSpec(FreewayDeterministic-v0), EnvSpec(FreewayDeterministic-v4), EnvSpec(FreewayNoFrameskip-v0), EnvSpec(FreewayNoFrameskip-v4), EnvSpec(Freeway-ram-v0), EnvSpec(Freeway-ram-v4), EnvSpec(Freeway-ramDeterministic-v0), EnvSpec(Freeway-ramDeterministic-v4), EnvSpec(Freeway-ramNoFrameskip-v0), EnvSpec(Freeway-ramNoFrameskip-v4), EnvSpec(Frostbite-v0), EnvSpec(Frostbite-v4), EnvSpec(FrostbiteDeterministic-v0), EnvSpec(FrostbiteDeterministic-v4), EnvSpec(FrostbiteNoFrameskip-v0), EnvSpec(FrostbiteNoFrameskip-v4), EnvSpec(Frostbite-ram-v0), EnvSpec(Frostbite-ram-v4), EnvSpec(Frostbite-ramDeterministic-v0), EnvSpec(Frostbite-ramDeterministic-v4), EnvSpec(Frostbite-ramNoFrameskip-v0), EnvSpec(Frostbite-ramNoFrameskip-v4), EnvSpec(Gopher-v0), EnvSpec(Gopher-v4), EnvSpec(GopherDeterministic-v0), EnvSpec(GopherDeterministic-v4), EnvSpec(GopherNoFrameskip-v0), EnvSpec(GopherNoFrameskip-v4), EnvSpec(Gopher-ram-v0), EnvSpec(Gopher-ram-v4), EnvSpec(Gopher-ramDeterministic-v0), EnvSpec(Gopher-ramDeterministic-v4), EnvSpec(Gopher-ramNoFrameskip-v0), EnvSpec(Gopher-ramNoFrameskip-v4), EnvSpec(Gravitar-v0), EnvSpec(Gravitar-v4), EnvSpec(GravitarDeterministic-v0), EnvSpec(GravitarDeterministic-v4), EnvSpec(GravitarNoFrameskip-v0), EnvSpec(GravitarNoFrameskip-v4), EnvSpec(Gravitar-ram-v0), EnvSpec(Gravitar-ram-v4), EnvSpec(Gravitar-ramDeterministic-v0), EnvSpec(Gravitar-ramDeterministic-v4), EnvSpec(Gravitar-ramNoFrameskip-v0), EnvSpec(Gravitar-ramNoFrameskip-v4), EnvSpec(Hero-v0), EnvSpec(Hero-v4), EnvSpec(HeroDeterministic-v0), EnvSpec(HeroDeterministic-v4), EnvSpec(HeroNoFrameskip-v0), EnvSpec(HeroNoFrameskip-v4), EnvSpec(Hero-ram-v0), EnvSpec(Hero-ram-v4), EnvSpec(Hero-ramDeterministic-v0), EnvSpec(Hero-ramDeterministic-v4), EnvSpec(Hero-ramNoFrameskip-v0), EnvSpec(Hero-ramNoFrameskip-v4), EnvSpec(IceHockey-v0), EnvSpec(IceHockey-v4), EnvSpec(IceHockeyDeterministic-v0), EnvSpec(IceHockeyDeterministic-v4), EnvSpec(IceHockeyNoFrameskip-v0), EnvSpec(IceHockeyNoFrameskip-v4), EnvSpec(IceHockey-ram-v0), EnvSpec(IceHockey-ram-v4), EnvSpec(IceHockey-ramDeterministic-v0), EnvSpec(IceHockey-ramDeterministic-v4), EnvSpec(IceHockey-ramNoFrameskip-v0), EnvSpec(IceHockey-ramNoFrameskip-v4), EnvSpec(Jamesbond-v0), EnvSpec(Jamesbond-v4), EnvSpec(JamesbondDeterministic-v0), EnvSpec(JamesbondDeterministic-v4), EnvSpec(JamesbondNoFrameskip-v0), EnvSpec(JamesbondNoFrameskip-v4), EnvSpec(Jamesbond-ram-v0), EnvSpec(Jamesbond-ram-v4), EnvSpec(Jamesbond-ramDeterministic-v0), EnvSpec(Jamesbond-ramDeterministic-v4), EnvSpec(Jamesbond-ramNoFrameskip-v0), EnvSpec(Jamesbond-ramNoFrameskip-v4), EnvSpec(JourneyEscape-v0), EnvSpec(JourneyEscape-v4), EnvSpec(JourneyEscapeDeterministic-v0), EnvSpec(JourneyEscapeDeterministic-v4), EnvSpec(JourneyEscapeNoFrameskip-v0), EnvSpec(JourneyEscapeNoFrameskip-v4), EnvSpec(JourneyEscape-ram-v0), EnvSpec(JourneyEscape-ram-v4), EnvSpec(JourneyEscape-ramDeterministic-v0), EnvSpec(JourneyEscape-ramDeterministic-v4), EnvSpec(JourneyEscape-ramNoFrameskip-v0), EnvSpec(JourneyEscape-ramNoFrameskip-v4), EnvSpec(Kangaroo-v0), EnvSpec(Kangaroo-v4), EnvSpec(KangarooDeterministic-v0), EnvSpec(KangarooDeterministic-v4), EnvSpec(KangarooNoFrameskip-v0), EnvSpec(KangarooNoFrameskip-v4), EnvSpec(Kangaroo-ram-v0), EnvSpec(Kangaroo-ram-v4), EnvSpec(Kangaroo-ramDeterministic-v0), EnvSpec(Kangaroo-ramDeterministic-v4), EnvSpec(Kangaroo-ramNoFrameskip-v0), EnvSpec(Kangaroo-ramNoFrameskip-v4), EnvSpec(Krull-v0), EnvSpec(Krull-v4), EnvSpec(KrullDeterministic-v0), EnvSpec(KrullDeterministic-v4), EnvSpec(KrullNoFrameskip-v0), EnvSpec(KrullNoFrameskip-v4), EnvSpec(Krull-ram-v0), EnvSpec(Krull-ram-v4), EnvSpec(Krull-ramDeterministic-v0), EnvSpec(Krull-ramDeterministic-v4), EnvSpec(Krull-ramNoFrameskip-v0), EnvSpec(Krull-ramNoFrameskip-v4), EnvSpec(KungFuMaster-v0), EnvSpec(KungFuMaster-v4), EnvSpec(KungFuMasterDeterministic-v0), EnvSpec(KungFuMasterDeterministic-v4), EnvSpec(KungFuMasterNoFrameskip-v0), EnvSpec(KungFuMasterNoFrameskip-v4), EnvSpec(KungFuMaster-ram-v0), EnvSpec(KungFuMaster-ram-v4), EnvSpec(KungFuMaster-ramDeterministic-v0), EnvSpec(KungFuMaster-ramDeterministic-v4), EnvSpec(KungFuMaster-ramNoFrameskip-v0), EnvSpec(KungFuMaster-ramNoFrameskip-v4), EnvSpec(MontezumaRevenge-v0), EnvSpec(MontezumaRevenge-v4), EnvSpec(MontezumaRevengeDeterministic-v0), EnvSpec(MontezumaRevengeDeterministic-v4), EnvSpec(MontezumaRevengeNoFrameskip-v0), EnvSpec(MontezumaRevengeNoFrameskip-v4), EnvSpec(MontezumaRevenge-ram-v0), EnvSpec(MontezumaRevenge-ram-v4), EnvSpec(MontezumaRevenge-ramDeterministic-v0), EnvSpec(MontezumaRevenge-ramDeterministic-v4), EnvSpec(MontezumaRevenge-ramNoFrameskip-v0), EnvSpec(MontezumaRevenge-ramNoFrameskip-v4), EnvSpec(MsPacman-v0), EnvSpec(MsPacman-v4), EnvSpec(MsPacmanDeterministic-v0), EnvSpec(MsPacmanDeterministic-v4), EnvSpec(MsPacmanNoFrameskip-v0), EnvSpec(MsPacmanNoFrameskip-v4), EnvSpec(MsPacman-ram-v0), EnvSpec(MsPacman-ram-v4), EnvSpec(MsPacman-ramDeterministic-v0), EnvSpec(MsPacman-ramDeterministic-v4), EnvSpec(MsPacman-ramNoFrameskip-v0), EnvSpec(MsPacman-ramNoFrameskip-v4), EnvSpec(NameThisGame-v0), EnvSpec(NameThisGame-v4), EnvSpec(NameThisGameDeterministic-v0), EnvSpec(NameThisGameDeterministic-v4), EnvSpec(NameThisGameNoFrameskip-v0), EnvSpec(NameThisGameNoFrameskip-v4), EnvSpec(NameThisGame-ram-v0), EnvSpec(NameThisGame-ram-v4), EnvSpec(NameThisGame-ramDeterministic-v0), EnvSpec(NameThisGame-ramDeterministic-v4), EnvSpec(NameThisGame-ramNoFrameskip-v0), EnvSpec(NameThisGame-ramNoFrameskip-v4), EnvSpec(Phoenix-v0), EnvSpec(Phoenix-v4), EnvSpec(PhoenixDeterministic-v0), EnvSpec(PhoenixDeterministic-v4), EnvSpec(PhoenixNoFrameskip-v0), EnvSpec(PhoenixNoFrameskip-v4), EnvSpec(Phoenix-ram-v0), EnvSpec(Phoenix-ram-v4), EnvSpec(Phoenix-ramDeterministic-v0), EnvSpec(Phoenix-ramDeterministic-v4), EnvSpec(Phoenix-ramNoFrameskip-v0), EnvSpec(Phoenix-ramNoFrameskip-v4), EnvSpec(Pitfall-v0), EnvSpec(Pitfall-v4), EnvSpec(PitfallDeterministic-v0), EnvSpec(PitfallDeterministic-v4), EnvSpec(PitfallNoFrameskip-v0), EnvSpec(PitfallNoFrameskip-v4), EnvSpec(Pitfall-ram-v0), EnvSpec(Pitfall-ram-v4), EnvSpec(Pitfall-ramDeterministic-v0), EnvSpec(Pitfall-ramDeterministic-v4), EnvSpec(Pitfall-ramNoFrameskip-v0), EnvSpec(Pitfall-ramNoFrameskip-v4), EnvSpec(Pong-v0), EnvSpec(Pong-v4), EnvSpec(PongDeterministic-v0), EnvSpec(PongDeterministic-v4), EnvSpec(PongNoFrameskip-v0), EnvSpec(PongNoFrameskip-v4), EnvSpec(Pong-ram-v0), EnvSpec(Pong-ram-v4), EnvSpec(Pong-ramDeterministic-v0), EnvSpec(Pong-ramDeterministic-v4), EnvSpec(Pong-ramNoFrameskip-v0), EnvSpec(Pong-ramNoFrameskip-v4), EnvSpec(Pooyan-v0), EnvSpec(Pooyan-v4), EnvSpec(PooyanDeterministic-v0), EnvSpec(PooyanDeterministic-v4), EnvSpec(PooyanNoFrameskip-v0), EnvSpec(PooyanNoFrameskip-v4), EnvSpec(Pooyan-ram-v0), EnvSpec(Pooyan-ram-v4), EnvSpec(Pooyan-ramDeterministic-v0), EnvSpec(Pooyan-ramDeterministic-v4), EnvSpec(Pooyan-ramNoFrameskip-v0), EnvSpec(Pooyan-ramNoFrameskip-v4), EnvSpec(PrivateEye-v0), EnvSpec(PrivateEye-v4), EnvSpec(PrivateEyeDeterministic-v0), EnvSpec(PrivateEyeDeterministic-v4), EnvSpec(PrivateEyeNoFrameskip-v0), EnvSpec(PrivateEyeNoFrameskip-v4), EnvSpec(PrivateEye-ram-v0), EnvSpec(PrivateEye-ram-v4), EnvSpec(PrivateEye-ramDeterministic-v0), EnvSpec(PrivateEye-ramDeterministic-v4), EnvSpec(PrivateEye-ramNoFrameskip-v0), EnvSpec(PrivateEye-ramNoFrameskip-v4), EnvSpec(Qbert-v0), EnvSpec(Qbert-v4), EnvSpec(QbertDeterministic-v0), EnvSpec(QbertDeterministic-v4), EnvSpec(QbertNoFrameskip-v0), EnvSpec(QbertNoFrameskip-v4), EnvSpec(Qbert-ram-v0), EnvSpec(Qbert-ram-v4), EnvSpec(Qbert-ramDeterministic-v0), EnvSpec(Qbert-ramDeterministic-v4), EnvSpec(Qbert-ramNoFrameskip-v0), EnvSpec(Qbert-ramNoFrameskip-v4), EnvSpec(Riverraid-v0), EnvSpec(Riverraid-v4), EnvSpec(RiverraidDeterministic-v0), EnvSpec(RiverraidDeterministic-v4), EnvSpec(RiverraidNoFrameskip-v0), EnvSpec(RiverraidNoFrameskip-v4), EnvSpec(Riverraid-ram-v0), EnvSpec(Riverraid-ram-v4), EnvSpec(Riverraid-ramDeterministic-v0), EnvSpec(Riverraid-ramDeterministic-v4), EnvSpec(Riverraid-ramNoFrameskip-v0), EnvSpec(Riverraid-ramNoFrameskip-v4), EnvSpec(RoadRunner-v0), EnvSpec(RoadRunner-v4), EnvSpec(RoadRunnerDeterministic-v0), EnvSpec(RoadRunnerDeterministic-v4), EnvSpec(RoadRunnerNoFrameskip-v0), EnvSpec(RoadRunnerNoFrameskip-v4), EnvSpec(RoadRunner-ram-v0), EnvSpec(RoadRunner-ram-v4), EnvSpec(RoadRunner-ramDeterministic-v0), EnvSpec(RoadRunner-ramDeterministic-v4), EnvSpec(RoadRunner-ramNoFrameskip-v0), EnvSpec(RoadRunner-ramNoFrameskip-v4), EnvSpec(Robotank-v0), EnvSpec(Robotank-v4), EnvSpec(RobotankDeterministic-v0), EnvSpec(RobotankDeterministic-v4), EnvSpec(RobotankNoFrameskip-v0), EnvSpec(RobotankNoFrameskip-v4), EnvSpec(Robotank-ram-v0), EnvSpec(Robotank-ram-v4), EnvSpec(Robotank-ramDeterministic-v0), EnvSpec(Robotank-ramDeterministic-v4), EnvSpec(Robotank-ramNoFrameskip-v0), EnvSpec(Robotank-ramNoFrameskip-v4), EnvSpec(Seaquest-v0), EnvSpec(Seaquest-v4), EnvSpec(SeaquestDeterministic-v0), EnvSpec(SeaquestDeterministic-v4), EnvSpec(SeaquestNoFrameskip-v0), EnvSpec(SeaquestNoFrameskip-v4), EnvSpec(Seaquest-ram-v0), EnvSpec(Seaquest-ram-v4), EnvSpec(Seaquest-ramDeterministic-v0), EnvSpec(Seaquest-ramDeterministic-v4), EnvSpec(Seaquest-ramNoFrameskip-v0), EnvSpec(Seaquest-ramNoFrameskip-v4), EnvSpec(Skiing-v0), EnvSpec(Skiing-v4), EnvSpec(SkiingDeterministic-v0), EnvSpec(SkiingDeterministic-v4), EnvSpec(SkiingNoFrameskip-v0), EnvSpec(SkiingNoFrameskip-v4), EnvSpec(Skiing-ram-v0), EnvSpec(Skiing-ram-v4), EnvSpec(Skiing-ramDeterministic-v0), EnvSpec(Skiing-ramDeterministic-v4), EnvSpec(Skiing-ramNoFrameskip-v0), EnvSpec(Skiing-ramNoFrameskip-v4), EnvSpec(Solaris-v0), EnvSpec(Solaris-v4), EnvSpec(SolarisDeterministic-v0), EnvSpec(SolarisDeterministic-v4), EnvSpec(SolarisNoFrameskip-v0), EnvSpec(SolarisNoFrameskip-v4), EnvSpec(Solaris-ram-v0), EnvSpec(Solaris-ram-v4), EnvSpec(Solaris-ramDeterministic-v0), EnvSpec(Solaris-ramDeterministic-v4), EnvSpec(Solaris-ramNoFrameskip-v0), EnvSpec(Solaris-ramNoFrameskip-v4), EnvSpec(SpaceInvaders-v0), EnvSpec(SpaceInvaders-v4), EnvSpec(SpaceInvadersDeterministic-v0), EnvSpec(SpaceInvadersDeterministic-v4), EnvSpec(SpaceInvadersNoFrameskip-v0), EnvSpec(SpaceInvadersNoFrameskip-v4), EnvSpec(SpaceInvaders-ram-v0), EnvSpec(SpaceInvaders-ram-v4), EnvSpec(SpaceInvaders-ramDeterministic-v0), EnvSpec(SpaceInvaders-ramDeterministic-v4), EnvSpec(SpaceInvaders-ramNoFrameskip-v0), EnvSpec(SpaceInvaders-ramNoFrameskip-v4), EnvSpec(StarGunner-v0), EnvSpec(StarGunner-v4), EnvSpec(StarGunnerDeterministic-v0), EnvSpec(StarGunnerDeterministic-v4), EnvSpec(StarGunnerNoFrameskip-v0), EnvSpec(StarGunnerNoFrameskip-v4), EnvSpec(StarGunner-ram-v0), EnvSpec(StarGunner-ram-v4), EnvSpec(StarGunner-ramDeterministic-v0), EnvSpec(StarGunner-ramDeterministic-v4), EnvSpec(StarGunner-ramNoFrameskip-v0), EnvSpec(StarGunner-ramNoFrameskip-v4), EnvSpec(Tennis-v0), EnvSpec(Tennis-v4), EnvSpec(TennisDeterministic-v0), EnvSpec(TennisDeterministic-v4), EnvSpec(TennisNoFrameskip-v0), EnvSpec(TennisNoFrameskip-v4), EnvSpec(Tennis-ram-v0), EnvSpec(Tennis-ram-v4), EnvSpec(Tennis-ramDeterministic-v0), EnvSpec(Tennis-ramDeterministic-v4), EnvSpec(Tennis-ramNoFrameskip-v0), EnvSpec(Tennis-ramNoFrameskip-v4), EnvSpec(TimePilot-v0), EnvSpec(TimePilot-v4), EnvSpec(TimePilotDeterministic-v0), EnvSpec(TimePilotDeterministic-v4), EnvSpec(TimePilotNoFrameskip-v0), EnvSpec(TimePilotNoFrameskip-v4), EnvSpec(TimePilot-ram-v0), EnvSpec(TimePilot-ram-v4), EnvSpec(TimePilot-ramDeterministic-v0), EnvSpec(TimePilot-ramDeterministic-v4), EnvSpec(TimePilot-ramNoFrameskip-v0), EnvSpec(TimePilot-ramNoFrameskip-v4), EnvSpec(Tutankham-v0), EnvSpec(Tutankham-v4), EnvSpec(TutankhamDeterministic-v0), EnvSpec(TutankhamDeterministic-v4), EnvSpec(TutankhamNoFrameskip-v0), EnvSpec(TutankhamNoFrameskip-v4), EnvSpec(Tutankham-ram-v0), EnvSpec(Tutankham-ram-v4), EnvSpec(Tutankham-ramDeterministic-v0), EnvSpec(Tutankham-ramDeterministic-v4), EnvSpec(Tutankham-ramNoFrameskip-v0), EnvSpec(Tutankham-ramNoFrameskip-v4), EnvSpec(UpNDown-v0), EnvSpec(UpNDown-v4), EnvSpec(UpNDownDeterministic-v0), EnvSpec(UpNDownDeterministic-v4), EnvSpec(UpNDownNoFrameskip-v0), EnvSpec(UpNDownNoFrameskip-v4), EnvSpec(UpNDown-ram-v0), EnvSpec(UpNDown-ram-v4), EnvSpec(UpNDown-ramDeterministic-v0), EnvSpec(UpNDown-ramDeterministic-v4), EnvSpec(UpNDown-ramNoFrameskip-v0), EnvSpec(UpNDown-ramNoFrameskip-v4), EnvSpec(Venture-v0), EnvSpec(Venture-v4), EnvSpec(VentureDeterministic-v0), EnvSpec(VentureDeterministic-v4), EnvSpec(VentureNoFrameskip-v0), EnvSpec(VentureNoFrameskip-v4), EnvSpec(Venture-ram-v0), EnvSpec(Venture-ram-v4), EnvSpec(Venture-ramDeterministic-v0), EnvSpec(Venture-ramDeterministic-v4), EnvSpec(Venture-ramNoFrameskip-v0), EnvSpec(Venture-ramNoFrameskip-v4), EnvSpec(VideoPinball-v0), EnvSpec(VideoPinball-v4), EnvSpec(VideoPinballDeterministic-v0), EnvSpec(VideoPinballDeterministic-v4), EnvSpec(VideoPinballNoFrameskip-v0), EnvSpec(VideoPinballNoFrameskip-v4), EnvSpec(VideoPinball-ram-v0), EnvSpec(VideoPinball-ram-v4), EnvSpec(VideoPinball-ramDeterministic-v0), EnvSpec(VideoPinball-ramDeterministic-v4), EnvSpec(VideoPinball-ramNoFrameskip-v0), EnvSpec(VideoPinball-ramNoFrameskip-v4), EnvSpec(WizardOfWor-v0), EnvSpec(WizardOfWor-v4), EnvSpec(WizardOfWorDeterministic-v0), EnvSpec(WizardOfWorDeterministic-v4), EnvSpec(WizardOfWorNoFrameskip-v0), EnvSpec(WizardOfWorNoFrameskip-v4), EnvSpec(WizardOfWor-ram-v0), EnvSpec(WizardOfWor-ram-v4), EnvSpec(WizardOfWor-ramDeterministic-v0), EnvSpec(WizardOfWor-ramDeterministic-v4), EnvSpec(WizardOfWor-ramNoFrameskip-v0), EnvSpec(WizardOfWor-ramNoFrameskip-v4), EnvSpec(YarsRevenge-v0), EnvSpec(YarsRevenge-v4), EnvSpec(YarsRevengeDeterministic-v0), EnvSpec(YarsRevengeDeterministic-v4), EnvSpec(YarsRevengeNoFrameskip-v0), EnvSpec(YarsRevengeNoFrameskip-v4), EnvSpec(YarsRevenge-ram-v0), EnvSpec(YarsRevenge-ram-v4), EnvSpec(YarsRevenge-ramDeterministic-v0), EnvSpec(YarsRevenge-ramDeterministic-v4), EnvSpec(YarsRevenge-ramNoFrameskip-v0), EnvSpec(YarsRevenge-ramNoFrameskip-v4), EnvSpec(Zaxxon-v0), EnvSpec(Zaxxon-v4), EnvSpec(ZaxxonDeterministic-v0), EnvSpec(ZaxxonDeterministic-v4), EnvSpec(ZaxxonNoFrameskip-v0), EnvSpec(ZaxxonNoFrameskip-v4), EnvSpec(Zaxxon-ram-v0), EnvSpec(Zaxxon-ram-v4), EnvSpec(Zaxxon-ramDeterministic-v0), EnvSpec(Zaxxon-ramDeterministic-v4), EnvSpec(Zaxxon-ramNoFrameskip-v0), EnvSpec(Zaxxon-ramNoFrameskip-v4), EnvSpec(CubeCrash-v0), EnvSpec(CubeCrashSparse-v0), EnvSpec(CubeCrashScreenBecomesBlack-v0), EnvSpec(MemorizeDigits-v0)])\n"
          ]
        }
      ],
      "source": [
        "from gym import envs\n",
        "print(envs.registry.all()) # check if 'FrozenLake-v1' and 'FrozenLake8x8-v1' are among the environments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "ZA3QF3XQP5Hf"
      },
      "source": [
        "In the code provided below, an agent taking random actions is interacting with this environment (i.e., the initial policy is a deterministic random policy)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "_ts1pGQjP5Hf"
      },
      "outputs": [],
      "source": [
        "def run_episodes(environment, n_episodes, policy, display=True):\n",
        "    wins = 0\n",
        "    total_reward = 0\n",
        "    for episode in range(n_episodes):\n",
        "        terminated = False\n",
        "        state = environment.reset()\n",
        "        while not terminated:\n",
        "            # Select an action to perform in a current state\n",
        "            if policy == 'random':\n",
        "                action = environment.action_space.sample()\n",
        "            else:\n",
        "                action = np.argmax(policy[state])\n",
        "\n",
        "            # Perform an action and observe how environment acted in response\n",
        "            next_state, reward, terminated, info = environment.step(action)\n",
        "\n",
        "            # Plot the first episode\n",
        "            if episode==1 and display:\n",
        "                print(\"Action:\")\n",
        "                environment.render() # display current agent state\n",
        "            # Summarize total reward\n",
        "            total_reward += reward\n",
        "            # Update current state\n",
        "            state = next_state\n",
        "            # Calculate number of wins over episodes\n",
        "            if terminated and reward == 1.0:\n",
        "                wins += 1\n",
        "    average_reward = total_reward / n_episodes\n",
        "    return wins, total_reward, average_reward"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32i2b03MP5Hg",
        "outputId": "b859119c-0b06-4d14-b72a-cf0c5a5983d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First episode:\n",
            "Action:\n",
            "  (Left)\n",
            "SFFF\n",
            "\u001b[41mF\u001b[0mHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Action:\n",
            "  (Left)\n",
            "SFFF\n",
            "FHFH\n",
            "\u001b[41mF\u001b[0mFFH\n",
            "HFFG\n",
            "Action:\n",
            "  (Left)\n",
            "SFFF\n",
            "FHFH\n",
            "\u001b[41mF\u001b[0mFFH\n",
            "HFFG\n",
            "Action:\n",
            "  (Down)\n",
            "SFFF\n",
            "FHFH\n",
            "\u001b[41mF\u001b[0mFFH\n",
            "HFFG\n",
            "Action:\n",
            "  (Up)\n",
            "SFFF\n",
            "FHFH\n",
            "F\u001b[41mF\u001b[0mFH\n",
            "HFFG\n",
            "Action:\n",
            "  (Down)\n",
            "SFFF\n",
            "FHFH\n",
            "FF\u001b[41mF\u001b[0mH\n",
            "HFFG\n",
            "Action:\n",
            "  (Left)\n",
            "SFFF\n",
            "FH\u001b[41mF\u001b[0mH\n",
            "FFFH\n",
            "HFFG\n",
            "Action:\n",
            "  (Up)\n",
            "SFFF\n",
            "F\u001b[41mH\u001b[0mFH\n",
            "FFFH\n",
            "HFFG\n",
            "------------------------------------\n",
            "Summary:\n",
            "- number of wins over 5000 episodes = 68\n",
            "- average reward over 5000 episodes = 0.0136\n"
          ]
        }
      ],
      "source": [
        "# Load a Frozen Lake environment\n",
        "env = gym.make('FrozenLake-v0')\n",
        "# Number of episodes to play\n",
        "n_episodes = 5000\n",
        "# First episode plotted as a sample episode\n",
        "print('First episode:')\n",
        "wins, total_reward, average_reward = run_episodes(env, n_episodes, policy=\"random\")\n",
        "print('------------------------------------')\n",
        "print('Summary:')\n",
        "print(f'- number of wins over {n_episodes} episodes = {wins}')\n",
        "print(f'- average reward over {n_episodes} episodes = {average_reward}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "DtzXu-4UP5Hh"
      },
      "source": [
        "**a**) Implement the Iterative Policy Evaluation algorithm as a function to evaluate the given policy. How many iterations does the random policy need to converge?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "LlgXIhReP5Hi"
      },
      "outputs": [],
      "source": [
        "def policy_evaluation(policy, environment, discount_factor=1.0, theta=1e-9, max_iterations=1e9):\n",
        "    # Number of evaluation iterations\n",
        "    evaluation_iterations = 1\n",
        "    # Initialize a value function for each state as zero\n",
        "    V = np.zeros(environment.nS)\n",
        "    # Repeat until change in value is below the threshold\n",
        "    for i in range(int(max_iterations)):\n",
        "        # Initialize a change of value function as zero\n",
        "        delta = 0\n",
        "        # Iterate though each state\n",
        "        for state in range(environment.nS):\n",
        "            # TODO your code here\n",
        "            v= V[state]\n",
        "            # print(\"policy evaluation: v= \", v)\n",
        "            action_values = []\n",
        "            for action, prob_action in enumerate(policy[state]):\n",
        "              state_value = 0\n",
        "              for i in range(len(env.P[state][action])):\n",
        "                prob_next_state, next_state, reward, terminated = env.P[state][action][i]\n",
        "                state_action_value = prob_next_state * (reward + discount_factor *V[next_state])\n",
        "                state_value += state_action_value\n",
        "              action_values.append(prob_action * state_value)\n",
        "            V[state] =sum(action_values)  \n",
        "            # Calculate the absolute change of value function\n",
        "            delta = max(delta, np.abs(V[state] - v))\n",
        "            # Update value function\n",
        "        evaluation_iterations += 1\n",
        "        # Terminate if value change is insignificant\n",
        "        if delta < theta:\n",
        "            print(f'Policy-iteration converged at iteration #{i}.')\n",
        "            return V"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "Ivei5ToTP5Hj"
      },
      "source": [
        "**b**) Using your Policy Evaluation function from (a), implement the Policy iteration algorithm. Run the Policy iteration to obtain the optimal policy for the `FrozenLake-v1` environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "CKa4dI3lP5Hk"
      },
      "outputs": [],
      "source": [
        "def one_step_lookahead(environment, state, V, discount_factor):\n",
        "    action_values = np.zeros(environment.nA)\n",
        "    for action in range(environment.nA):\n",
        "        for probability, next_state, reward, terminated in environment.P[state][action]:\n",
        "            action_values[action] += probability * (reward + discount_factor * V[next_state])\n",
        "    return action_values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "def policy_iteration(environment, discount_factor=1.0, max_iterations=1e9):\n",
        "    # Start with a random policy\n",
        "    # num states x num actions / num actions\n",
        "    policy = np.ones([environment.nS, environment.nA]) / environment.nA\n",
        "    # Initialize counter of evaluated policies\n",
        "    evaluated_policies = 1\n",
        "    # Repeat until convergence or critical number of iterations reached\n",
        "    for i in range(int(max_iterations)):\n",
        "        stable_policy = True\n",
        "        # Evaluate current policy\n",
        "        V = policy_evaluation(policy, environment, discount_factor=discount_factor)\n",
        "        # Go through each state and try to improve actions that were taken (policy Improvement)\n",
        "        for state in range(environment.nS):\n",
        "            # Choose the best action in a current state under current policy\n",
        "            current_action = np.argmax(policy[state])\n",
        "            # Look one step ahead and evaluate if current action is optimal\n",
        "            # We will try every possible action in a current state\n",
        "            action_value = one_step_lookahead(environment, state, V, discount_factor)\n",
        "            # Select a better action\n",
        "            action_values = []\n",
        "            for action in range(env.nA):\n",
        "              state_value =0\n",
        "              for i in range(len(environment.P[state][action])):\n",
        "                prob_next_state, next_state, reward, terminated = env.P[state][action][i]\n",
        "                # print(prob,next_state,reward)\n",
        "                state_action_value =prob_next_state * (reward + (discount_factor* V[next_state]))\n",
        "                # print(state_action_value)\n",
        "                state_value += state_action_value\n",
        "              action_values.append(state_value)\n",
        "            # print(action_values)  \n",
        "            best_action = np.argmax(action_values) \n",
        "            # If action didn't change\n",
        "            if current_action != best_action:\n",
        "                stable_policy = False\n",
        "                # Greedy policy update\n",
        "                policy[state] = np.eye(environment.nA)[best_action]\n",
        "        evaluated_policies += 1\n",
        "        # If the algorithm converged and policy is not changing anymore, then return final policy and value function\n",
        "        if stable_policy:\n",
        "            return policy, V"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "7vOmm2fRP5Hk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Policy-iteration converged at iteration #0.\n",
            "Policy-iteration converged at iteration #0.\n",
            "Policy-iteration converged at iteration #0.\n",
            "Action:\n",
            "  (Left)\n",
            "SFFF\n",
            "\u001b[41mF\u001b[0mHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Action:\n",
            "  (Left)\n",
            "\u001b[41mS\u001b[0mFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Action:\n",
            "  (Left)\n",
            "\u001b[41mS\u001b[0mFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Action:\n",
            "  (Left)\n",
            "SFFF\n",
            "\u001b[41mF\u001b[0mHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Action:\n",
            "  (Left)\n",
            "SFFF\n",
            "\u001b[41mF\u001b[0mHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Action:\n",
            "  (Left)\n",
            "SFFF\n",
            "\u001b[41mF\u001b[0mHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Action:\n",
            "  (Left)\n",
            "\u001b[41mS\u001b[0mFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Action:\n",
            "  (Left)\n",
            "\u001b[41mS\u001b[0mFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Action:\n",
            "  (Left)\n",
            "\u001b[41mS\u001b[0mFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Action:\n",
            "  (Left)\n",
            "\u001b[41mS\u001b[0mFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Action:\n",
            "  (Left)\n",
            "SFFF\n",
            "\u001b[41mF\u001b[0mHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Action:\n",
            "  (Left)\n",
            "\u001b[41mS\u001b[0mFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Action:\n",
            "  (Left)\n",
            "\u001b[41mS\u001b[0mFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Action:\n",
            "  (Left)\n",
            "\u001b[41mS\u001b[0mFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Action:\n",
            "  (Left)\n",
            "\u001b[41mS\u001b[0mFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Action:\n",
            "  (Left)\n",
            "\u001b[41mS\u001b[0mFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Action:\n",
            "  (Left)\n",
            "\u001b[41mS\u001b[0mFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Action:\n",
            "  (Left)\n",
            "\u001b[41mS\u001b[0mFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Action:\n",
            "  (Left)\n",
            "\u001b[41mS\u001b[0mFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Action:\n",
            "  (Left)\n",
            "\u001b[41mS\u001b[0mFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Action:\n",
            "  (Left)\n",
            "SFFF\n",
            "\u001b[41mF\u001b[0mHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Action:\n",
            "  (Left)\n",
            "\u001b[41mS\u001b[0mFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Action:\n",
            "  (Left)\n",
            "\u001b[41mS\u001b[0mFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Action:\n",
            "  (Left)\n",
            "\u001b[41mS\u001b[0mFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Action:\n",
            "  (Left)\n",
            "\u001b[41mS\u001b[0mFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Action:\n",
            "  (Left)\n",
            "\u001b[41mS\u001b[0mFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Action:\n",
            "  (Left)\n",
            "\u001b[41mS\u001b[0mFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Action:\n",
            "  (Left)\n",
            "\u001b[41mS\u001b[0mFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Action:\n",
            "  (Left)\n",
            "\u001b[41mS\u001b[0mFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Action:\n",
            "  (Left)\n",
            "SFFF\n",
            "\u001b[41mF\u001b[0mHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Action:\n",
            "  (Left)\n",
            "SFFF\n",
            "FHFH\n",
            "\u001b[41mF\u001b[0mFFH\n",
            "HFFG\n",
            "Action:\n",
            "  (Up)\n",
            "SFFF\n",
            "\u001b[41mF\u001b[0mHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Action:\n",
            "  (Left)\n",
            "SFFF\n",
            "FHFH\n",
            "\u001b[41mF\u001b[0mFFH\n",
            "HFFG\n",
            "Action:\n",
            "  (Up)\n",
            "SFFF\n",
            "FHFH\n",
            "F\u001b[41mF\u001b[0mFH\n",
            "HFFG\n",
            "Action:\n",
            "  (Down)\n",
            "SFFF\n",
            "FHFH\n",
            "\u001b[41mF\u001b[0mFFH\n",
            "HFFG\n",
            "Action:\n",
            "  (Up)\n",
            "SFFF\n",
            "\u001b[41mF\u001b[0mHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Action:\n",
            "  (Left)\n",
            "SFFF\n",
            "\u001b[41mF\u001b[0mHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Action:\n",
            "  (Left)\n",
            "SFFF\n",
            "FHFH\n",
            "\u001b[41mF\u001b[0mFFH\n",
            "HFFG\n",
            "Action:\n",
            "  (Up)\n",
            "SFFF\n",
            "FHFH\n",
            "F\u001b[41mF\u001b[0mFH\n",
            "HFFG\n",
            "Action:\n",
            "  (Down)\n",
            "SFFF\n",
            "FHFH\n",
            "FFFH\n",
            "H\u001b[41mF\u001b[0mFG\n",
            "Action:\n",
            "  (Right)\n",
            "SFFF\n",
            "FHFH\n",
            "FFFH\n",
            "H\u001b[41mF\u001b[0mFG\n",
            "Action:\n",
            "  (Right)\n",
            "SFFF\n",
            "FHFH\n",
            "F\u001b[41mF\u001b[0mFH\n",
            "HFFG\n",
            "Action:\n",
            "  (Down)\n",
            "SFFF\n",
            "FHFH\n",
            "FFFH\n",
            "H\u001b[41mF\u001b[0mFG\n",
            "Action:\n",
            "  (Right)\n",
            "SFFF\n",
            "FHFH\n",
            "FFFH\n",
            "H\u001b[41mF\u001b[0mFG\n",
            "Action:"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
            "  if __name__ == '__main__':\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  (Right)\n",
            "SFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HF\u001b[41mF\u001b[0mG\n",
            "Action:\n",
            "  (Down)\n",
            "SFFF\n",
            "FHFH\n",
            "FFFH\n",
            "H\u001b[41mF\u001b[0mFG\n",
            "Action:\n",
            "  (Right)\n",
            "SFFF\n",
            "FHFH\n",
            "F\u001b[41mF\u001b[0mFH\n",
            "HFFG\n",
            "Action:\n",
            "  (Down)\n",
            "SFFF\n",
            "FHFH\n",
            "\u001b[41mF\u001b[0mFFH\n",
            "HFFG\n",
            "Action:\n",
            "  (Up)\n",
            "SFFF\n",
            "FHFH\n",
            "\u001b[41mF\u001b[0mFFH\n",
            "HFFG\n",
            "Action:\n",
            "  (Up)\n",
            "SFFF\n",
            "FHFH\n",
            "F\u001b[41mF\u001b[0mFH\n",
            "HFFG\n",
            "Action:\n",
            "  (Down)\n",
            "SFFF\n",
            "FHFH\n",
            "FF\u001b[41mF\u001b[0mH\n",
            "HFFG\n",
            "Action:\n",
            "  (Left)\n",
            "SFFF\n",
            "FHFH\n",
            "F\u001b[41mF\u001b[0mFH\n",
            "HFFG\n",
            "Action:\n",
            "  (Down)\n",
            "SFFF\n",
            "FHFH\n",
            "FFFH\n",
            "H\u001b[41mF\u001b[0mFG\n",
            "Action:\n",
            "  (Right)\n",
            "SFFF\n",
            "FHFH\n",
            "F\u001b[41mF\u001b[0mFH\n",
            "HFFG\n",
            "Action:\n",
            "  (Down)\n",
            "SFFF\n",
            "FHFH\n",
            "FF\u001b[41mF\u001b[0mH\n",
            "HFFG\n",
            "Action:\n",
            "  (Left)\n",
            "SFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HF\u001b[41mF\u001b[0mG\n",
            "Action:\n",
            "  (Down)\n",
            "SFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HF\u001b[41mF\u001b[0mG\n",
            "Action:\n",
            "  (Down)\n",
            "SFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HF\u001b[41mF\u001b[0mG\n",
            "Action:\n",
            "  (Down)\n",
            "SFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFF\u001b[41mG\u001b[0m\n",
            "Policy iteration: number of wins over 1000 episodes = 733\n",
            "Policy iteration: average reward over 1000 episodes = 0.733 \n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Number of episodes to play\n",
        "n_episodes = 1000\n",
        "iteration_name = \"Policy iteration\"\n",
        "iteration_func = policy_iteration\n",
        "# Load a Frozen Lake environment\n",
        "environment = gym.make('FrozenLake-v0')\n",
        "# Search for an optimal policy using policy iteration\n",
        "policy, V = iteration_func(environment.env)\n",
        "# Apply best policy to the real environment\n",
        "wins, total_reward, average_reward = run_episodes(environment, n_episodes, policy)\n",
        "print(f'{iteration_name}: number of wins over {n_episodes} episodes = {wins}')\n",
        "print(f'{iteration_name}: average reward over {n_episodes} episodes = {average_reward} \\n\\n')"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hvq-Ty8dP5Hl",
        "outputId": "cfee5796-ecc0-4b8c-92db-dd932f632469"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "TRKCB9bkP5Hl"
      },
      "source": [
        "**c**) Implement the Value iteration algorithm. Run the algorithm to obtain the optimal policy for the `FrozenLake-v1` environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "JIt4GN-OP5Hl"
      },
      "outputs": [],
      "source": [
        "def value_iteration(environment, discount_factor=1.0, theta=1e-9, max_iterations=1e9):\n",
        "    # Initialize state-value function with zeros for each environment state\n",
        "    V = np.zeros(environment.nS)\n",
        "    for i in range(int(max_iterations)):\n",
        "        # Early stopping condition\n",
        "        delta = 0\n",
        "        # Update each state\n",
        "        for state in range(environment.nS):\n",
        "            # Do a one-step lookahead to calculate state-action values\n",
        "            action_value = one_step_lookahead(environment, state, V, discount_factor)\n",
        "            # Select best action to perform based on the highest state-action value\n",
        "            best_action_value = max(action_value)\n",
        "            # Calculate change in value\n",
        "            delta = max(delta, np.abs(V[state] - best_action_value))\n",
        "            # Update the value function for current state\n",
        "            V[state] = best_action_value\n",
        "            # Check if we can stop\n",
        "        if delta < theta:\n",
        "            print(f'Value-iteration converged at iteration #{i}.')\n",
        "            break\n",
        "\n",
        "    # Create a deterministic policy using the optimal value function\n",
        "    policy = np.zeros([environment.nS, environment.nA])\n",
        "    for state in range(environment.nS):\n",
        "        # One step lookahead to find the best action for this state\n",
        "        action_value = one_step_lookahead(environment, state, V, discount_factor)\n",
        "        # Select best action based on the highest state-action value\n",
        "        best_action = np.argmax(action_value)\n",
        "        # Update the policy to perform a better action at a current state\n",
        "        policy[state, best_action] = 1.0\n",
        "    return policy, V"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Number of episodes to play\n",
        "n_episodes = 1000\n",
        "iteration_name = \"Value iteration\"\n",
        "iteration_func = value_iteration\n",
        "# Load a Frozen Lake environment\n",
        "environment = gym.make('FrozenLake-v0')\n",
        "# Search for an optimal policy using policy iteration\n",
        "policy, V = iteration_func(environment.env)\n",
        "# Apply best policy to the real environment\n",
        "wins, total_reward, average_reward = run_episodes(environment, n_episodes, policy)\n",
        "print(f'{iteration_name}: number of wins over {n_episodes} episodes = {wins}')\n",
        "print(f'{iteration_name}: average reward over {n_episodes} episodes = {average_reward} \\n\\n')"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "UDcy2mS-P5Hm"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "IUT2B5hDP5Hm"
      },
      "source": [
        "**d**) Compare two optimal policies in part (b) and (c). Which seems to converge faster and why?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "13XvXtMiP5Hm"
      },
      "outputs": [],
      "source": [
        "# Number of episodes to play\n",
        "n_episodes = 5000\n",
        "# Functions to find best policy\n",
        "solvers = [('Policy Iteration', policy_iteration),\n",
        "           ('Value Iteration', value_iteration)]\n",
        "for iteration_name, iteration_func in solvers:\n",
        "    # Load a Frozen Lake environment\n",
        "    environment = gym.make('FrozenLake-v0')\n",
        "    # Search for an optimal policy using policy iteration\n",
        "    policy, V = iteration_func(environment.env)\n",
        "    # Apply best policy to the real environment\n",
        "    wins, total_reward, average_reward = run_episodes(environment, n_episodes, policy)\n",
        "    print(f'{iteration_name} :: number of wins over {n_episodes} episodes = {wins}')\n",
        "    print(f'{iteration_name} :: average reward over {n_episodes} episodes = {average_reward} \\n\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "DZV8A6dCP5Hm"
      },
      "source": [
        "**e**) Run the Policy Iteration and the Value Iteration algorithms on a bigger environment, FrozenLake8x8-v1. Compare the convergence speed of algorithms for both environments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "vCvJ1Wh5P5Hn"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "vU5HGGdEP5Hn"
      },
      "source": [
        "---\n",
        "#### **2. Gambler's problem**\n",
        "\n",
        "*(4 x 1.25 points)*\n",
        "\n",
        "Consider an agent placing bets on the outcomes of a sequence of coin flips. It the coin toss results in `heads`, the gambler's return is equal to the bet he placed, if the outcome is `tails`, the opposite happens and the gambler looses the bet. The coin lands on heads 40% of the time. The game continues until the gambler has either lost all his capital or reaches his goal of earning $100$.\n",
        "\n",
        "**Problem summary:**\n",
        "- Undiscounted, finite, episodic MDP: $\\gamma=1$ and there is a terminal state\n",
        "- State: gambler's capital $s \\in \\{ 0, 1, 2, ..., 100 \\}$\n",
        "- Actions: the bet $a = \\{ 0, 1, ..., \\mathrm{min}(s, 100-s)\\}$\n",
        "- Policy: maps the current capital available to how much the agent should bet\n",
        "- Terminal states: capital=0 or capital=100\n",
        "- Reward: 0 for all states, except when the goal is reached (capital=100), where it is +1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "EuIYz178P5Hn"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "xUdGgItWP5Hn"
      },
      "outputs": [],
      "source": [
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "lyMNqsYfP5Hn"
      },
      "outputs": [],
      "source": [
        "goal = 100\n",
        "states = np.arange(goal + 1)\n",
        "\n",
        "p_head = 0.4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "hzCrladKP5Ho"
      },
      "source": [
        "**a**) The state-value function gives the probability of winning from each state. Perform value iteration and plot the value of each state in different iterations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "3Oy84x6HP5Ho"
      },
      "outputs": [],
      "source": [
        "# initial values\n",
        "state_value = np.zeros(goal + 1)\n",
        "state_value[goal] = 1.0\n",
        "sweeps_history = []\n",
        "\n",
        "# value iteration\n",
        "while True:\n",
        "    old_state_value = state_value.copy()\n",
        "    sweeps_history.append(old_state_value)\n",
        "\n",
        "    for state in states[1:goal]:\n",
        "        # get possilbe actions for current state\n",
        "        actions = range(0, (min(state, (100 - state)))+1 )\n",
        "        action_returns = []\n",
        "        for action in actions:\n",
        "            returns = (p_head * action,-(1-p_head) * action)  \n",
        "            action_returns.extend(returns)\n",
        "        new_value = max(action_returns)\n",
        "        state_value[state] = new_value\n",
        "    delta = abs(state_value - old_state_value).max()\n",
        "    if delta < 1e-9:\n",
        "        sweeps_history.append(state_value)\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Value estimates')"
            ]
          },
          "metadata": {},
          "execution_count": 48
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.figure(figsize=(10, 5))\n",
        "for sweep, state_value in enumerate(sweeps_history):\n",
        "    plt.plot(state_value, label='sweep {}'.format(sweep))\n",
        "plt.xlabel('Capital')\n",
        "plt.ylabel('Value estimates')"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "KbUND-VlP5Ho",
        "outputId": "63e97197-553f-44eb-9bbb-e1114fa295d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        }
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "Ovgi_AL2P5Hp"
      },
      "source": [
        "**b**) Compute and plot the optimal policy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "fzWGKY6cP5Hp"
      },
      "outputs": [],
      "source": [
        "# compute the optimal policy\n",
        "policy = np.zeros(goal + 1)\n",
        "for state in states[1:goal]:\n",
        "    # actions =\n",
        "    action_returns = []\n",
        "    for action in actions:\n",
        "        # returns =\n",
        "        action_returns.append(returns)\n",
        "    policy[state] = actions[np.argmax(np.round(action_returns[1:], 5)) + 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(states, policy)\n",
        "plt.xlabel('Capital')\n",
        "plt.ylabel('Final policy')"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "v_9XgaBEP5Hp"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "bosAfVokP5Hp"
      },
      "source": [
        "**c**) Re-using your value iteration code provided above, plot the results obtained if $p_{h}=0.25$ and $p_{h}=0.62$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "5-FHwTCBP5Hq"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "ws0-XQBfP5Hq"
      },
      "source": [
        "**d**) Compute and plot the corresponding optimal policies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "qSXj9RU9P5Hq"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "name": "3-DynamicProgramming-assignments.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}